{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction The purpose of the resource is to provide more in-depth technical documentaion on the SRT protocol and library. Videos SRT Protocol Overview IETF 107 Presentation Maxim Sharabayko. March 2020. SRT: How the hot new UDP video protocol actually works under the hood. Alex Converse. August 2019 Useful Links SRT RFC draft: link UDT Documentation The official Debian package and the configuration files: link SRT: How the hot new UDP video protocol actually works under the hood - Alex Converse | August 2019. YouTube","title":"Introduction"},{"location":"#introduction","text":"The purpose of the resource is to provide more in-depth technical documentaion on the SRT protocol and library.","title":"Introduction"},{"location":"#videos","text":"","title":"Videos"},{"location":"#srt-protocol-overview-ietf-107-presentation","text":"Maxim Sharabayko. March 2020.","title":"SRT Protocol Overview IETF 107 Presentation"},{"location":"#srt-how-the-hot-new-udp-video-protocol-actually-works-under-the-hood","text":"Alex Converse. August 2019","title":"SRT: How the hot new UDP video protocol actually works under the hood."},{"location":"#useful-links","text":"SRT RFC draft: link UDT Documentation The official Debian package and the configuration files: link SRT: How the hot new UDP video protocol actually works under the hood - Alex Converse | August 2019. YouTube","title":"Useful Links"},{"location":"faq/","text":"FAQ What applications support SRT? See the list here . Open source: srt-live-transmit, FFmpeg, WireShark, GStreamer, liquidsoap, OBS Studio, Eyevinn Toolbox . Corporate: Haivision Media Gateway, Haivision KB, Haivision Makito X I get error messages \"tsbpd wrap period begins/ends\". What does it mean? Messages about TSBPD wrap period are informational. These are not errors. SRT just informs that the timer used to track packets is close to overflow and is ready to be reset. There is nothing you should do about that. It is just to inform about this situation. For more information please see the TSBPD Wrapping Period section. Issues on GitHub: #642 . I get error messages \"No room to store incoming packet...\" What does it mean? This error message is usually related to the buffer sizes. See also #703. The Default receiver buffer size is approximately 96 Mbits. This buffer should store all the packets within the specified latency, and also have some space for the application to read (FFmpeg). You might probably need to increase the buffer size, by appending to the following URI \"srt://0.0.0.0:9999?pkt_size=1316&mode=listener\" the following querry values can be added: sndbuf - Send buffer size (in bytes) rcvbuf - Receive buffer size (in bytes) Other FFmpeg SRT URI options can be found here .","title":"FAQ"},{"location":"faq/#faq","text":"","title":"FAQ"},{"location":"faq/#what-applications-support-srt","text":"See the list here . Open source: srt-live-transmit, FFmpeg, WireShark, GStreamer, liquidsoap, OBS Studio, Eyevinn Toolbox . Corporate: Haivision Media Gateway, Haivision KB, Haivision Makito X","title":"What applications support SRT?"},{"location":"faq/#i-get-error-messages-tsbpd-wrap-period-beginsends-what-does-it-mean","text":"Messages about TSBPD wrap period are informational. These are not errors. SRT just informs that the timer used to track packets is close to overflow and is ready to be reset. There is nothing you should do about that. It is just to inform about this situation. For more information please see the TSBPD Wrapping Period section. Issues on GitHub: #642 .","title":"I get error messages \"tsbpd wrap period begins/ends\". What does it mean?"},{"location":"faq/#i-get-error-messages-no-room-to-store-incoming-packet-what-does-it-mean","text":"This error message is usually related to the buffer sizes. See also #703. The Default receiver buffer size is approximately 96 Mbits. This buffer should store all the packets within the specified latency, and also have some space for the application to read (FFmpeg). You might probably need to increase the buffer size, by appending to the following URI \"srt://0.0.0.0:9999?pkt_size=1316&mode=listener\" the following querry values can be added: sndbuf - Send buffer size (in bytes) rcvbuf - Receive buffer size (in bytes) Other FFmpeg SRT URI options can be found here .","title":"I get error messages \"No room to store incoming packet...\" What does it mean?"},{"location":"apps/","text":"Projects and Applications with SRT support SRT is used by thousands of organizations globally in a wide range of industry applications, from IP cameras, video encoders and decoders to gateways, OTT platforms and CDNs. SRT has also been adopted by leading industry open source technologies including VLC by VideoLAN, GStreamer, Wireshark, FFmpeg, Libav, and OBS Studio. Sample Applications srt-live-transmit srt-xtransmit Open Source Projects GStreamer [Website] [Configuration Tips] Wireshark [Website] [Configuration Tips] FFmpeg [Website] [Configuration Tips] Libav [Website] OBS Studio [Website] [GitHub] [Configuration Tips] TSDuck [Website] [GitHub] [Configuration Tips] Free of Charge Players with SRT support VLC Media Player [Website] [Configuration Tips] FFPlay [Website] [Configuration Tips (FFMpeg)] MPV [Website] [PR submitted] Haivision Play Pro [AppStore] [Google Play] Haivision Play [AppStore] [Google Play] Larix Player [AppStore] [Google Play] Free of Charge Mobile Streaming Apps with SRT support Haivision Play Pro [AppStore] [Google Play] Larix Broadcaster [AppStore] [Google Play] Larix Screencaster [AppStore] [Google Play]","title":"Projects and Applications with SRT support"},{"location":"apps/#projects-and-applications-with-srt-support","text":"SRT is used by thousands of organizations globally in a wide range of industry applications, from IP cameras, video encoders and decoders to gateways, OTT platforms and CDNs. SRT has also been adopted by leading industry open source technologies including VLC by VideoLAN, GStreamer, Wireshark, FFmpeg, Libav, and OBS Studio.","title":"Projects and Applications with SRT support"},{"location":"apps/#sample-applications","text":"srt-live-transmit srt-xtransmit","title":"Sample Applications"},{"location":"apps/#open-source-projects","text":"GStreamer [Website] [Configuration Tips] Wireshark [Website] [Configuration Tips] FFmpeg [Website] [Configuration Tips] Libav [Website] OBS Studio [Website] [GitHub] [Configuration Tips] TSDuck [Website] [GitHub] [Configuration Tips]","title":"Open Source Projects"},{"location":"apps/#free-of-charge-players-with-srt-support","text":"VLC Media Player [Website] [Configuration Tips] FFPlay [Website] [Configuration Tips (FFMpeg)] MPV [Website] [PR submitted] Haivision Play Pro [AppStore] [Google Play] Haivision Play [AppStore] [Google Play] Larix Player [AppStore] [Google Play]","title":"Free of Charge Players with SRT support"},{"location":"apps/#free-of-charge-mobile-streaming-apps-with-srt-support","text":"Haivision Play Pro [AppStore] [Google Play] Larix Broadcaster [AppStore] [Google Play] Larix Screencaster [AppStore] [Google Play]","title":"Free of Charge Mobile Streaming Apps with SRT support"},{"location":"apps/ffmpeg/","text":"FFmpeg Building FFmpeg with SRT FFmpeg supports the SRT protocol out of the box. To include SRT, FFmpeg project should be built with the configure flag --enable-libsrt . Refer to FFmpeg's Compilation Guide for the detailed build instructions for a particular platform. Please check Quickstart: Running SRT and FFmpeg on Ubuntu YouTube Video for additional instructions. Note There is a feedback that SRT cannot be built by FFmpeg if both --enable-libsrt and --enable-shared options are specified. A list of available protocols can be determined by calling ffmpeg -protocols . \"srt\" (or \"libsrt\") should be listed as both input and output protocol. General Usage Once SRT is available, an SRT output can be specified like this: \"srt://<destination_ip>:<destination_port>\" Note Note that FFmpeg expects SRT latency to be specified in microseconds, not milliseconds as it's done in the SRT library. The following URI sets the SRT latency to be 400 milliseconds: srt://<ip>:<port>?latency=400000 . It's recommended to use MPEG-TS as a container: -f mpegts . ffplay should be able to play SRT streaming with ffplay srt://<ip>:<port> . Piping can be done like this: srt-live-transmit srt://<ip>:<port> file://con | ffplay -f mpegts - Please take into account issue #407 . Or pipe via UDP socket on a localhost: srt-live-transmit srt://<ip>:<port> udp://127.0.0.1:<portB> ffplay udp://127.0.0.1:<portB> -f mpegts In the latest case the -f mpegts argument is optional. Note -re option will slow down the reading: \"Read input at native frame rate. Mainly used to simulate a grab device, or live input stream (e.g. when reading from a file). Should not be used with ... live input streams (where it can cause packet loss). By default ffmpeg attempts to read the input(s) as fast as possible. This option will slow down the reading of the input(s) to the native frame rate of the input(s). It is useful for real-time output (e.g. live streaming)\". Examples FFmpeg example: Grabbing X11 desktop screen and streaming to SRT ffmpeg -f x11grab -follow_mouse centered -r 25 -s cif -i :0.0 \\ -f mpegts srt://<target_ip>:<target_port> FFmpeg example with SMPTE bars test video source ffmpeg -f lavfi -re -i smptebars=duration=60:size=1280x720:rate=30 -f lavfi -re \\ -i sine=frequency=1000:duration=60:sample_rate=44100 -pix_fmt yuv420p \\ -c:v libx264 -b:v 1000k -g 30 -keyint_min 120 -profile:v baseline \\ -preset veryfast -f mpegts \"srt://127.0.0.1:4200?pkt_size=1316\" FFmpeg example: RTSP to SRT ffmpeg -i rtsp://<src_rtsp_uri> -c copy -f mpegts srt://<target_srt_uri> See also rtsp2srt project. Example with FFmpeg and srt-live-transmit test application Send to UDP localhost port 5000: ffmpeg -f lavfi -re -i smptebars=duration=60:size=1280x720:rate=30 -f lavfi -re \\ -i sine=frequency=1000:duration=60:sample_rate=44100 -pix_fmt yuv420p \\ -c:v libx264 -b:v 1000k -g 30 -keyint_min 120 -profile:v baseline \\ -preset veryfast -f mpegts \"udp://127.0.0.1:5000?pkt_size=1316\" Transmit from UDP to SRT destination: ./srt-live-transmit udp://:5000 srt://<ip>:<port>?mode=rendezvous Receive with SRT: ./srt-live-transmit srt://<ip>:<port>?mode=rendezvous file://con > ./received.ts Receive SRT and pass to /dev/nul : `./ffmpeg -i srt://<ip>:<port> -f null /dev/null`","title":"FFmpeg"},{"location":"apps/ffmpeg/#ffmpeg","text":"","title":"FFmpeg"},{"location":"apps/ffmpeg/#building-ffmpeg-with-srt","text":"FFmpeg supports the SRT protocol out of the box. To include SRT, FFmpeg project should be built with the configure flag --enable-libsrt . Refer to FFmpeg's Compilation Guide for the detailed build instructions for a particular platform. Please check Quickstart: Running SRT and FFmpeg on Ubuntu YouTube Video for additional instructions. Note There is a feedback that SRT cannot be built by FFmpeg if both --enable-libsrt and --enable-shared options are specified. A list of available protocols can be determined by calling ffmpeg -protocols . \"srt\" (or \"libsrt\") should be listed as both input and output protocol.","title":"Building FFmpeg with SRT"},{"location":"apps/ffmpeg/#general-usage","text":"Once SRT is available, an SRT output can be specified like this: \"srt://<destination_ip>:<destination_port>\" Note Note that FFmpeg expects SRT latency to be specified in microseconds, not milliseconds as it's done in the SRT library. The following URI sets the SRT latency to be 400 milliseconds: srt://<ip>:<port>?latency=400000 . It's recommended to use MPEG-TS as a container: -f mpegts . ffplay should be able to play SRT streaming with ffplay srt://<ip>:<port> . Piping can be done like this: srt-live-transmit srt://<ip>:<port> file://con | ffplay -f mpegts - Please take into account issue #407 . Or pipe via UDP socket on a localhost: srt-live-transmit srt://<ip>:<port> udp://127.0.0.1:<portB> ffplay udp://127.0.0.1:<portB> -f mpegts In the latest case the -f mpegts argument is optional. Note -re option will slow down the reading: \"Read input at native frame rate. Mainly used to simulate a grab device, or live input stream (e.g. when reading from a file). Should not be used with ... live input streams (where it can cause packet loss). By default ffmpeg attempts to read the input(s) as fast as possible. This option will slow down the reading of the input(s) to the native frame rate of the input(s). It is useful for real-time output (e.g. live streaming)\".","title":"General Usage"},{"location":"apps/ffmpeg/#examples","text":"","title":"Examples"},{"location":"apps/ffmpeg/#ffmpeg-example-grabbing-x11-desktop-screen-and-streaming-to-srt","text":"ffmpeg -f x11grab -follow_mouse centered -r 25 -s cif -i :0.0 \\ -f mpegts srt://<target_ip>:<target_port>","title":"FFmpeg example: Grabbing X11 desktop screen and streaming to SRT"},{"location":"apps/ffmpeg/#ffmpeg-example-with-smpte-bars-test-video-source","text":"ffmpeg -f lavfi -re -i smptebars=duration=60:size=1280x720:rate=30 -f lavfi -re \\ -i sine=frequency=1000:duration=60:sample_rate=44100 -pix_fmt yuv420p \\ -c:v libx264 -b:v 1000k -g 30 -keyint_min 120 -profile:v baseline \\ -preset veryfast -f mpegts \"srt://127.0.0.1:4200?pkt_size=1316\"","title":"FFmpeg example with SMPTE bars test video source"},{"location":"apps/ffmpeg/#ffmpeg-example-rtsp-to-srt","text":"ffmpeg -i rtsp://<src_rtsp_uri> -c copy -f mpegts srt://<target_srt_uri> See also rtsp2srt project.","title":"FFmpeg example: RTSP to SRT"},{"location":"apps/ffmpeg/#example-with-ffmpeg-and-srt-live-transmit-test-application","text":"Send to UDP localhost port 5000: ffmpeg -f lavfi -re -i smptebars=duration=60:size=1280x720:rate=30 -f lavfi -re \\ -i sine=frequency=1000:duration=60:sample_rate=44100 -pix_fmt yuv420p \\ -c:v libx264 -b:v 1000k -g 30 -keyint_min 120 -profile:v baseline \\ -preset veryfast -f mpegts \"udp://127.0.0.1:5000?pkt_size=1316\" Transmit from UDP to SRT destination: ./srt-live-transmit udp://:5000 srt://<ip>:<port>?mode=rendezvous Receive with SRT: ./srt-live-transmit srt://<ip>:<port>?mode=rendezvous file://con > ./received.ts Receive SRT and pass to /dev/nul : `./ffmpeg -i srt://<ip>:<port> -f null /dev/null`","title":"Example with FFmpeg and srt-live-transmit test application"},{"location":"apps/gstreamer-plugin/","text":"GStreamer Starting from ver. 1.14 GStreamer supports SRT (see the v.1.14 release notes ). See the SRT plugin for GStreamer on git . Using GStreamer and SRT to set up a screensharing Based on the description in #7 . Note that the commands are likely to change slightly for gstreamer 1.16 (see this issue ). If you don't want to build GSteamer, SRT, and all the plugins from source or don't have a distribution that has 1.14 readily available, you can use nix to reproduce what is shown further. Simply install nix ; then use the command bellow to open a shell where the following commands work. NIX_PATH=nixpkgs=https://github.com/nh2/nixpkgs/archive/a94ff5f6aaa.tar.gz \\ nix-shell -p gst_all_1.gstreamer \\ -p gst_all_1.gst-plugins-good -p gst_all_1.gst-plugins-base \\ -p gst_all_1.gst-plugins-bad \\ -p gst_all_1.gst-plugins-ugly -p gst_all_1.gst-libav Sender server Set up a sender server that will grab a source raw video from a desktop or a webcam, encode it with x.264 (H.264/AVC) encoder, pack it in MPEG-TS ( more info about live streaming ). Then pipe it into the SRT sink that sends it over the network to the receiver client. The streaming URI should looks like uri=srt://<ip>:<port> . In the examples below the streaming is sent to port 888 on a localhost by specifying uri=srt://0.0.0.0:8888 . For screensharing (Linux with X Display) The ximagesrc GStreamer plugin can be used to capture X Display and create raw RGB video. Refer to ximagesrc RM for configuration options. /usr/bin/time gst-launch-1.0 ximagesrc startx=0 show-pointer=true use-damage=0 \\ ! videoconvert \\ ! x264enc bitrate=32000 tune=zerolatency speed-preset=veryfast \\ byte-stream=true threads=1 key-int-max=15 \\ intra-refresh=true ! video/x-h264, profile=baseline, framerate=30/1 ! mpegtsmux \\ ! srtserversink uri=srt://0.0.0.0:8888/ latency=100 For webcam images The v4l2src GStreamer plugin can be used to capture video from v4l2 devices, like webcams and TV cards. Refer to v4l2src RM for further information. /usr/bin/time gst-launch-1.0 v4l2src ! videoconvert \\ ! x264enc bitrate=8000 tune=zerolatency speed-preset=superfast \\ byte-stream=true threads=1 key-int-max=15 intra-refresh=true \\ ! video/x-h264, profile=baseline ! mpegtsmux \\ ! srtserversink uri=srt://0.0.0.0:8888/ latency=100 Notes The decodebin can also be used to configure settings automatically. Using explicit pipeline elements here make it possible to tune the settings when needed. A use of time helps to determine when the thread is capped at 100%, while the the thread=1 parameter makes the encoding use only one thread. Remove threads=1 to allow multiple cores, or cjange the speed-preset to reduce CPU load. The timeout setting can be tuned. A recommended timeout is 2x-2.5x of the expected roundtrip time. The password functionality works as well, but only if a password is >= 10 characters long; otherwise it's completely ignored. See this bug of GStreamer. Receiver client A client connection over SRT to the server with URI srt://127.0.0.1:8888 (localhost) or a remote server is set up. URI syntax is srt://<ip>:<port> . Then MPEG-TS demuxer and video decoder is used to get a decompressed video, that goes to a playback plugin autovideosink . Note that multiple clients can connect to the server started earlier. gst-launch-1.0 srtclientsrc uri=srt://127.0.0.1:8888 ! tsdemux ! h264parse ! video/x-h264 ! avdec_h264 ! autovideosink sync=false This works over both the internet and localhost. Useful Links Oliver Cr\u00eate. SRT in GStreamer . 2018","title":"GStreamer"},{"location":"apps/gstreamer-plugin/#gstreamer","text":"Starting from ver. 1.14 GStreamer supports SRT (see the v.1.14 release notes ). See the SRT plugin for GStreamer on git .","title":"GStreamer"},{"location":"apps/gstreamer-plugin/#using-gstreamer-and-srt-to-set-up-a-screensharing","text":"Based on the description in #7 . Note that the commands are likely to change slightly for gstreamer 1.16 (see this issue ). If you don't want to build GSteamer, SRT, and all the plugins from source or don't have a distribution that has 1.14 readily available, you can use nix to reproduce what is shown further. Simply install nix ; then use the command bellow to open a shell where the following commands work. NIX_PATH=nixpkgs=https://github.com/nh2/nixpkgs/archive/a94ff5f6aaa.tar.gz \\ nix-shell -p gst_all_1.gstreamer \\ -p gst_all_1.gst-plugins-good -p gst_all_1.gst-plugins-base \\ -p gst_all_1.gst-plugins-bad \\ -p gst_all_1.gst-plugins-ugly -p gst_all_1.gst-libav","title":"Using GStreamer and SRT to set up a screensharing"},{"location":"apps/gstreamer-plugin/#sender-server","text":"Set up a sender server that will grab a source raw video from a desktop or a webcam, encode it with x.264 (H.264/AVC) encoder, pack it in MPEG-TS ( more info about live streaming ). Then pipe it into the SRT sink that sends it over the network to the receiver client. The streaming URI should looks like uri=srt://<ip>:<port> . In the examples below the streaming is sent to port 888 on a localhost by specifying uri=srt://0.0.0.0:8888 .","title":"Sender server"},{"location":"apps/gstreamer-plugin/#for-screensharing-linux-with-x-display","text":"The ximagesrc GStreamer plugin can be used to capture X Display and create raw RGB video. Refer to ximagesrc RM for configuration options. /usr/bin/time gst-launch-1.0 ximagesrc startx=0 show-pointer=true use-damage=0 \\ ! videoconvert \\ ! x264enc bitrate=32000 tune=zerolatency speed-preset=veryfast \\ byte-stream=true threads=1 key-int-max=15 \\ intra-refresh=true ! video/x-h264, profile=baseline, framerate=30/1 ! mpegtsmux \\ ! srtserversink uri=srt://0.0.0.0:8888/ latency=100","title":"For screensharing (Linux with X Display)"},{"location":"apps/gstreamer-plugin/#for-webcam-images","text":"The v4l2src GStreamer plugin can be used to capture video from v4l2 devices, like webcams and TV cards. Refer to v4l2src RM for further information. /usr/bin/time gst-launch-1.0 v4l2src ! videoconvert \\ ! x264enc bitrate=8000 tune=zerolatency speed-preset=superfast \\ byte-stream=true threads=1 key-int-max=15 intra-refresh=true \\ ! video/x-h264, profile=baseline ! mpegtsmux \\ ! srtserversink uri=srt://0.0.0.0:8888/ latency=100","title":"For webcam images"},{"location":"apps/gstreamer-plugin/#notes","text":"The decodebin can also be used to configure settings automatically. Using explicit pipeline elements here make it possible to tune the settings when needed. A use of time helps to determine when the thread is capped at 100%, while the the thread=1 parameter makes the encoding use only one thread. Remove threads=1 to allow multiple cores, or cjange the speed-preset to reduce CPU load. The timeout setting can be tuned. A recommended timeout is 2x-2.5x of the expected roundtrip time. The password functionality works as well, but only if a password is >= 10 characters long; otherwise it's completely ignored. See this bug of GStreamer.","title":"Notes"},{"location":"apps/gstreamer-plugin/#receiver-client","text":"A client connection over SRT to the server with URI srt://127.0.0.1:8888 (localhost) or a remote server is set up. URI syntax is srt://<ip>:<port> . Then MPEG-TS demuxer and video decoder is used to get a decompressed video, that goes to a playback plugin autovideosink . Note that multiple clients can connect to the server started earlier. gst-launch-1.0 srtclientsrc uri=srt://127.0.0.1:8888 ! tsdemux ! h264parse ! video/x-h264 ! avdec_h264 ! autovideosink sync=false This works over both the internet and localhost.","title":"Receiver client"},{"location":"apps/gstreamer-plugin/#useful-links","text":"Oliver Cr\u00eate. SRT in GStreamer . 2018","title":"Useful Links"},{"location":"apps/obs-studio/","text":"OBS Studio OBS Studio is a free and open source software for video recording and live streaming. Starting from version 25.0 OBS Studio supports SRT output. The usage of SRT protocol with OBS Studio is described in OBS wiki page \" Streaming with SRT or RIST protocols \". Notes SRT support was added in PR #1748 . Useful Links Streaming with SRT or RIST protocols: [web] . Low-latency and High Performance Streaming: [web]","title":"OBS Studio"},{"location":"apps/obs-studio/#obs-studio","text":"OBS Studio is a free and open source software for video recording and live streaming. Starting from version 25.0 OBS Studio supports SRT output. The usage of SRT protocol with OBS Studio is described in OBS wiki page \" Streaming with SRT or RIST protocols \".","title":"OBS Studio"},{"location":"apps/obs-studio/#notes","text":"SRT support was added in PR #1748 .","title":"Notes"},{"location":"apps/obs-studio/#useful-links","text":"Streaming with SRT or RIST protocols: [web] . Low-latency and High Performance Streaming: [web]","title":"Useful Links"},{"location":"apps/tsduck/","text":"TSDuck TSDuck is an extensible toolkit for MPEG/DVB transport streams. TSDuck is used in digital television systems for test, monitoring, integration, debug, lab, demo. In practice, TSDuck is used for: Transport stream acquisition or transmodulation, including DVB, ATSC, ISDB, ASI and IP multicast. Analyze transport streams, PSI/SI signalization, bitrates, timestamps. Monitor and report conditions on the stream (video and audio properties, bitrates, crypto-periods, signalization). On-the-fly transformation or injection of content and signalization. Modify, remove, rename, extract services. Work on live transport streams, DVB-S/C/T, ATSC, ASI, IP-TV, HTTP, HLS, SRT or offline transport stream files. Re-route transport streams to other applications. Receive from or send to specialized hardware such as cheap tuners, Dektec or HiDes devices and modulators. Extract or inject MPE, SCTE 35, extract Teletext, T2-MI. And more... For detailed information, guidelines and use cases, please visit TSDuck website . TSDuck Installation on Ubuntu 20.04 LTS This is a little how-to on building TSduck for Ubuntu 20.04 LTS with SRT support. Build from Source Building instructions See building instructions at: https://tsduck.io/doxy/building.html mkdir tsduck cd tsduck git clone https://github.com/tsduck/tsduck.git Execute the shell-script: build/install-prerequisites.sh It downloads and installs the requested packages which are necessary to build TSDuck. The list of packages and how to install them depend on the operating system distribution and version. Building without specialized dependencies In specific configurations, you may want to disable some external libraries such as libcurl or pcsc-lite . Of course, the corresponding features in TSDuck will be disabled but the impact is limited. For instance, disabling libcurl will disable the plugin http (the plugin will still be there but it will report an error when used). The following make variables can be defined: NOTEST : Do not build unitary tests. NODTAPI : No Dektec support, remove dependency to DTAPI . NOCURL : No HTTP support, remove dependency to libcurl . NOPCSC : No smartcard support, remove dependency to pcsc-lite . NOSRT : No SRT (Secure Reliable Transport), remove dependency to libsrt . NOTELETEXT : No Teletext support, remove teletext handling code. make NOPCSC=1 NOCURL=1 NODTAPI=1 To speed up the compilation time a optional number of parallel threads can be set with the option -j10 make would use 10 parallel processes: make -j10 NOPCSC=1 NOCURL=1 NODTAPI=1 Set PATH to run from directory On all Unix systems, the binaries, plugins and tests are built inside the bin subdirectory. To run a tool from its build directory, a few environment variables shall be defined (including $PATH ). A shell-script named setenv.sh in the build directory defines the appropriate environment for running binaries. Execute: source build/setenv.sh Note the usage of the source command to make sure that the environment variables are defined in the current shell. Example: $ source build/setenv.sh $ which tsp ~/tsduck/bin/release-x86_64-vmubuntu/tsp $ tsp --version tsp: TSDuck - The MPEG Transport Stream Toolkit - version 3.26-2313 Optionally install TSDuck on system sudo make install Cleaning up On Linux and macOS, the same cleanup task is achieved using the following command: make distclean How to replay a .ts file as a stream 1. Use tsanalyze to find out a bitrate of the stream tsanalyze /home/n00b/Videos/StressTest_4KP25_h264.ts =============================================================================== | TRANSPORT STREAM ANALYSIS REPORT | |=============================================================================| | Transport Stream Id: .......... 1 (0x0001) | Services: .............. 1 | | Bytes: ....................... 349,332,952 | PID's: Total: .......... 4 | | TS packets: .................... 1,858,154 | Clear: .......... 4 | | With invalid sync: .................. 0 | Scrambled: ...... 0 | | With transport error: ............... 0 | With PCR's: ..... 1 | | Suspect and ignored: ................ 0 | Unreferenced: ... 0 | |-----------------------------------------------------------------------------| | Transport stream bitrate, based on ....... 188 bytes/pkt 204 bytes/pkt | | User-specified: ................................... None None | | Estimated based on PCR's: ............... 55,933,494 b/s 60,693,792 b/s | ^^^^^^^^^^^^^^ |||||||||||||| bitrate of the stream 2. Replay .ts file as MPEG-TS UDP stream tsp -I file --infinite /home/n00b/Videos/StressTest_4KP25_h264.ts -P regulate --bitrate 55933496 -O ip 192.168.2.49:4904 The specification of bitrate of the stream can also be set automatically without use of the --bitrate option: tsp -I file --infinite /home/n00b/Videos/StressTest_4KP25_h264.ts -P regulate -O ip 192.168.2.49:4904 3. SRT as input or output Up to TSDuck version 3.25, the srt input plugin used the caller mode and the srt output plugin used the listener mode. From TSDuck version 3.26 onwards, the srt input and output plugins can indifferently use caller, listener or rendezvous modes, using the same consistent set of command line options. See the TSDuck user's guide for a complete reference. The following examples are based on version 3.26. 4. Replay .ts file as SRT-Listener stream Now it's time to get started. There are some differences with the TSDuck SRT implementation compared to other SRT applications. Typically you only specify a port without IP like srt://:4900 and a SRT-listener on port 4900 will be created. If you specify an IP:port combination, SRT typically would act as SRT-caller to that IP:port (e.g. srt://192.168.2.49:4900 ) With TSDuck, you can create a listener port and optionally specify the adapter, which it should listen on using --listener port or --listener interface:port . In this test the Linux machine has two interfaces and the one with IP 192.168.2.3 was chosen to act as listening interface. tsp -I file --infinite /home/n00b/Videos/StressTest_4KP25_h264.ts -P regulate -O srt --listener 192.168.2.3:4900 --transtype live --messageapi It is also possible to just specify the port without a particular interface to use: tsp -I file --infinite /home/n00b/Videos/StressTest_4KP25_h264.ts -P regulate -O srt --listener 4900 --transtype live --messageapi A detail worth mentioning: -O srt --listener \"[IP:]Port\" for tsp already specifies the usage of the SRT protocol. So there is no need to add the srt:// prefix to the IP or DNS-name. Adding it would actually result in an error. Now another SRT application can connect to that SRT stream on 192.168.2.3:4900 provided by tsp , e.g., srt-live-transmit sample application to flip it back to MPEG-TS. srt-live-transmit.exe srt://192.168.2.3:4900 udp://192.168.2.49:10002 Or VLC player: press CTRL+N to open a new network stream and type in URL srt://192.168.2.3:4900 to connect to the stream in this example. Analyzing incoming SRT stream Incoming SRT stream containing MPEG-TS one can also be analyzed. The following example would connect in caller mode to the SRT stream, which was sent out using tsp as described in the section above and perform an analysis for 10 seconds: tsp -I srt --caller 192.168.2.3:4900 --transtype live --messageapi -P until --seconds 10 -P analyze -O drop It would generate an output to stdout like this (shortened) =============================================================================== | TRANSPORT STREAM ANALYSIS REPORT | |=============================================================================| | Transport Stream Id: .......... 1 (0x0001) | Services: .............. 1 | | Bytes: ........................ 99,391,840 | PID's: Total: .......... 4 | | TS packets: ...................... 528,680 | Clear: .......... 4 | | With invalid sync: .................. 0 | Scrambled: ...... 0 | | With transport error: ............... 0 | With PCR's: ..... 1 | | Suspect and ignored: ................ 0 | Unreferenced: ... 0 | |-----------------------------------------------------------------------------| | Transport stream bitrate, based on ....... 188 bytes/pkt 204 bytes/pkt | | User-specified: ......................... 69,642,777 b/s 75,569,821 b/s | | Estimated based on PCR's: ............... 58,771,501 b/s 63,773,331 b/s | |-----------------------------------------------------------------------------| | Broadcast time: .................................... 11 sec (0 mn 11 sec) | |-----------------------------------------------------------------------------| | Srv Id Service Name Access Bitrate | | 0x0001 Service01 .................................... C 67,660,510 b/s | | | | Note 1: C=Clear, S=Scrambled | | Note 2: Unless specified otherwise, bitrates are based on 188 bytes/pkt | =============================================================================== ... Output was cut off here. For more details perform this on your stream or see the TSDuck user's guide .","title":"TSDuck"},{"location":"apps/tsduck/#tsduck","text":"TSDuck is an extensible toolkit for MPEG/DVB transport streams. TSDuck is used in digital television systems for test, monitoring, integration, debug, lab, demo. In practice, TSDuck is used for: Transport stream acquisition or transmodulation, including DVB, ATSC, ISDB, ASI and IP multicast. Analyze transport streams, PSI/SI signalization, bitrates, timestamps. Monitor and report conditions on the stream (video and audio properties, bitrates, crypto-periods, signalization). On-the-fly transformation or injection of content and signalization. Modify, remove, rename, extract services. Work on live transport streams, DVB-S/C/T, ATSC, ASI, IP-TV, HTTP, HLS, SRT or offline transport stream files. Re-route transport streams to other applications. Receive from or send to specialized hardware such as cheap tuners, Dektec or HiDes devices and modulators. Extract or inject MPE, SCTE 35, extract Teletext, T2-MI. And more... For detailed information, guidelines and use cases, please visit TSDuck website .","title":"TSDuck"},{"location":"apps/tsduck/#tsduck-installation-on-ubuntu-2004-lts","text":"This is a little how-to on building TSduck for Ubuntu 20.04 LTS with SRT support.","title":"TSDuck Installation on Ubuntu 20.04 LTS"},{"location":"apps/tsduck/#build-from-source","text":"","title":"Build from Source"},{"location":"apps/tsduck/#building-instructions","text":"See building instructions at: https://tsduck.io/doxy/building.html mkdir tsduck cd tsduck git clone https://github.com/tsduck/tsduck.git Execute the shell-script: build/install-prerequisites.sh It downloads and installs the requested packages which are necessary to build TSDuck. The list of packages and how to install them depend on the operating system distribution and version.","title":"Building instructions"},{"location":"apps/tsduck/#building-without-specialized-dependencies","text":"In specific configurations, you may want to disable some external libraries such as libcurl or pcsc-lite . Of course, the corresponding features in TSDuck will be disabled but the impact is limited. For instance, disabling libcurl will disable the plugin http (the plugin will still be there but it will report an error when used). The following make variables can be defined: NOTEST : Do not build unitary tests. NODTAPI : No Dektec support, remove dependency to DTAPI . NOCURL : No HTTP support, remove dependency to libcurl . NOPCSC : No smartcard support, remove dependency to pcsc-lite . NOSRT : No SRT (Secure Reliable Transport), remove dependency to libsrt . NOTELETEXT : No Teletext support, remove teletext handling code. make NOPCSC=1 NOCURL=1 NODTAPI=1 To speed up the compilation time a optional number of parallel threads can be set with the option -j10 make would use 10 parallel processes: make -j10 NOPCSC=1 NOCURL=1 NODTAPI=1","title":"Building without specialized dependencies"},{"location":"apps/tsduck/#set-path-to-run-from-directory","text":"On all Unix systems, the binaries, plugins and tests are built inside the bin subdirectory. To run a tool from its build directory, a few environment variables shall be defined (including $PATH ). A shell-script named setenv.sh in the build directory defines the appropriate environment for running binaries. Execute: source build/setenv.sh Note the usage of the source command to make sure that the environment variables are defined in the current shell. Example: $ source build/setenv.sh $ which tsp ~/tsduck/bin/release-x86_64-vmubuntu/tsp $ tsp --version tsp: TSDuck - The MPEG Transport Stream Toolkit - version 3.26-2313","title":"Set PATH to run from directory"},{"location":"apps/tsduck/#optionally-install-tsduck-on-system","text":"sudo make install","title":"Optionally install TSDuck on system"},{"location":"apps/tsduck/#cleaning-up","text":"On Linux and macOS, the same cleanup task is achieved using the following command: make distclean","title":"Cleaning up"},{"location":"apps/tsduck/#how-to-replay-a-ts-file-as-a-stream","text":"","title":"How to replay a .ts file as a stream"},{"location":"apps/tsduck/#1-use-tsanalyze-to-find-out-a-bitrate-of-the-stream","text":"tsanalyze /home/n00b/Videos/StressTest_4KP25_h264.ts =============================================================================== | TRANSPORT STREAM ANALYSIS REPORT | |=============================================================================| | Transport Stream Id: .......... 1 (0x0001) | Services: .............. 1 | | Bytes: ....................... 349,332,952 | PID's: Total: .......... 4 | | TS packets: .................... 1,858,154 | Clear: .......... 4 | | With invalid sync: .................. 0 | Scrambled: ...... 0 | | With transport error: ............... 0 | With PCR's: ..... 1 | | Suspect and ignored: ................ 0 | Unreferenced: ... 0 | |-----------------------------------------------------------------------------| | Transport stream bitrate, based on ....... 188 bytes/pkt 204 bytes/pkt | | User-specified: ................................... None None | | Estimated based on PCR's: ............... 55,933,494 b/s 60,693,792 b/s | ^^^^^^^^^^^^^^ |||||||||||||| bitrate of the stream","title":"1. Use tsanalyze to find out a bitrate of the stream"},{"location":"apps/tsduck/#2-replay-ts-file-as-mpeg-ts-udp-stream","text":"tsp -I file --infinite /home/n00b/Videos/StressTest_4KP25_h264.ts -P regulate --bitrate 55933496 -O ip 192.168.2.49:4904 The specification of bitrate of the stream can also be set automatically without use of the --bitrate option: tsp -I file --infinite /home/n00b/Videos/StressTest_4KP25_h264.ts -P regulate -O ip 192.168.2.49:4904","title":"2. Replay .ts file as MPEG-TS UDP stream"},{"location":"apps/tsduck/#3-srt-as-input-or-output","text":"Up to TSDuck version 3.25, the srt input plugin used the caller mode and the srt output plugin used the listener mode. From TSDuck version 3.26 onwards, the srt input and output plugins can indifferently use caller, listener or rendezvous modes, using the same consistent set of command line options. See the TSDuck user's guide for a complete reference. The following examples are based on version 3.26.","title":"3. SRT as input or output"},{"location":"apps/tsduck/#4-replay-ts-file-as-srt-listener-stream","text":"Now it's time to get started. There are some differences with the TSDuck SRT implementation compared to other SRT applications. Typically you only specify a port without IP like srt://:4900 and a SRT-listener on port 4900 will be created. If you specify an IP:port combination, SRT typically would act as SRT-caller to that IP:port (e.g. srt://192.168.2.49:4900 ) With TSDuck, you can create a listener port and optionally specify the adapter, which it should listen on using --listener port or --listener interface:port . In this test the Linux machine has two interfaces and the one with IP 192.168.2.3 was chosen to act as listening interface. tsp -I file --infinite /home/n00b/Videos/StressTest_4KP25_h264.ts -P regulate -O srt --listener 192.168.2.3:4900 --transtype live --messageapi It is also possible to just specify the port without a particular interface to use: tsp -I file --infinite /home/n00b/Videos/StressTest_4KP25_h264.ts -P regulate -O srt --listener 4900 --transtype live --messageapi A detail worth mentioning: -O srt --listener \"[IP:]Port\" for tsp already specifies the usage of the SRT protocol. So there is no need to add the srt:// prefix to the IP or DNS-name. Adding it would actually result in an error. Now another SRT application can connect to that SRT stream on 192.168.2.3:4900 provided by tsp , e.g., srt-live-transmit sample application to flip it back to MPEG-TS. srt-live-transmit.exe srt://192.168.2.3:4900 udp://192.168.2.49:10002 Or VLC player: press CTRL+N to open a new network stream and type in URL srt://192.168.2.3:4900 to connect to the stream in this example.","title":"4. Replay .ts file as SRT-Listener stream"},{"location":"apps/tsduck/#analyzing-incoming-srt-stream","text":"Incoming SRT stream containing MPEG-TS one can also be analyzed. The following example would connect in caller mode to the SRT stream, which was sent out using tsp as described in the section above and perform an analysis for 10 seconds: tsp -I srt --caller 192.168.2.3:4900 --transtype live --messageapi -P until --seconds 10 -P analyze -O drop It would generate an output to stdout like this (shortened) =============================================================================== | TRANSPORT STREAM ANALYSIS REPORT | |=============================================================================| | Transport Stream Id: .......... 1 (0x0001) | Services: .............. 1 | | Bytes: ........................ 99,391,840 | PID's: Total: .......... 4 | | TS packets: ...................... 528,680 | Clear: .......... 4 | | With invalid sync: .................. 0 | Scrambled: ...... 0 | | With transport error: ............... 0 | With PCR's: ..... 1 | | Suspect and ignored: ................ 0 | Unreferenced: ... 0 | |-----------------------------------------------------------------------------| | Transport stream bitrate, based on ....... 188 bytes/pkt 204 bytes/pkt | | User-specified: ......................... 69,642,777 b/s 75,569,821 b/s | | Estimated based on PCR's: ............... 58,771,501 b/s 63,773,331 b/s | |-----------------------------------------------------------------------------| | Broadcast time: .................................... 11 sec (0 mn 11 sec) | |-----------------------------------------------------------------------------| | Srv Id Service Name Access Bitrate | | 0x0001 Service01 .................................... C 67,660,510 b/s | | | | Note 1: C=Clear, S=Scrambled | | Note 2: Unless specified otherwise, bitrates are based on 188 bytes/pkt | =============================================================================== ... Output was cut off here. For more details perform this on your stream or see the TSDuck user's guide .","title":"Analyzing incoming SRT stream"},{"location":"apps/vlc-media-player/","text":"VLC Media Player VLC media player supports SRT as an input (starting from VLC version 3). SRT access module source code: link . To open an SRT stream go to the menu \"Media\" -> \"Open Network Stream\". Specfy the source URI in the format: srt://ip:port . Note that VLC does not parse URI query options, so the parameters passed in a query are ignored. For example, srt://ip:port?passphrase=123456789!@ is identical to a simple srt:ip:port . SRT options can be specified on the corresponding property page. Go to the menu \"Tools\" -> \"Preferences\". In the bottom-left corner select \"Show Settings: All\". Select \"SRT\" in the tree node of \"Input Codecs\" -> \"Access modules\".","title":"VLC Media Player"},{"location":"apps/vlc-media-player/#vlc-media-player","text":"VLC media player supports SRT as an input (starting from VLC version 3). SRT access module source code: link . To open an SRT stream go to the menu \"Media\" -> \"Open Network Stream\". Specfy the source URI in the format: srt://ip:port . Note that VLC does not parse URI query options, so the parameters passed in a query are ignored. For example, srt://ip:port?passphrase=123456789!@ is identical to a simple srt:ip:port . SRT options can be specified on the corresponding property page. Go to the menu \"Tools\" -> \"Preferences\". In the bottom-left corner select \"Show Settings: All\". Select \"SRT\" in the tree node of \"Input Codecs\" -> \"Access modules\".","title":"VLC Media Player"},{"location":"apps/wireshark/","text":"Wireshark Wireshark is the world\u2019s foremost and widely-used network protocol analyzer. It lets you see what\u2019s happening on your network at a microscopic level and is the de facto (and often de jure) standard across many commercial and non-profit enterprises, government agencies, and educational institutions. Using TShark & Wireshark to analyse SRT traffic: link For more detailed information, guidelines and use cases, please visit Wireshark website .","title":"Wireshark"},{"location":"apps/wireshark/#wireshark","text":"Wireshark is the world\u2019s foremost and widely-used network protocol analyzer. It lets you see what\u2019s happening on your network at a microscopic level and is the de facto (and often de jure) standard across many commercial and non-profit enterprises, government agencies, and educational institutions. Using TShark & Wireshark to analyse SRT traffic: link For more detailed information, guidelines and use cases, please visit Wireshark website .","title":"Wireshark"},{"location":"getting-started/build-on-windows/","text":"Build on Windows Using NuGet 1. Download and install OpenSSL for Windows. The 64-bit package can be downloaded from here: Win64OpenSSL_Light-1_1_1c.exe . (Note that the last letter or version number may be changed and older versions no longer available. If this isn't found, check here: http://slproweb.com/products/Win32OpenSSL.html ) It's expected to be installed in C:\\Program Files\\OpenSSL-Win64 . Add this path to the user's or system's environment variable PATH . 2. Install Pthreads for Windows nuget install cinegy.pthreads-win64 -version 2.9.1.17 -OutputDirectory C:\\pthread-win32 3. Install cmake for Windows. CMake dowload page . The CMake GUI will help you configure the project. 4. Generate Visual Studio Solution. Assuming you are currently in the cloned repo. mkdir _build & cd _build cmake ../ -G\"Visual Studio 16 2019\" -A x64 -DPTHREAD_INCLUDE_DIR=\"C:\\pthread-win32\\cinegy.pthreads-win64.2.9.1.17\\sources\" -DPTHREAD_LIBRARY=\"C:\\pthread-win32\\cinegy.pthreads-win64.2.9.1.17\\runtimes\\win-x64\\native\\release\\pthread_lib.lib\" cmake --build ./ --config Release CMake will try to find OpenSSL and pthreads. If any of the is not found, you can define the following variables to help CMake find them: OPENSSL_ROOT_DIR=<path to OpenSSL installation> OPENSSL_LIBRARIES=<path to all the openssl libraries to link> OPENSSL_INCLUDE_DIR=<path to the OpenSSL include dir> PTHREAD_INCLUDE_DIR=<path to where pthread.h lies> PTHREAD_LIBRARY=<path to pthread.lib> Using vcpkg","title":"Build on Windows"},{"location":"getting-started/build-on-windows/#build-on-windows","text":"","title":"Build on Windows"},{"location":"getting-started/build-on-windows/#using-nuget","text":"","title":"Using NuGet"},{"location":"getting-started/build-on-windows/#1-download-and-install-openssl-for-windows","text":"The 64-bit package can be downloaded from here: Win64OpenSSL_Light-1_1_1c.exe . (Note that the last letter or version number may be changed and older versions no longer available. If this isn't found, check here: http://slproweb.com/products/Win32OpenSSL.html ) It's expected to be installed in C:\\Program Files\\OpenSSL-Win64 . Add this path to the user's or system's environment variable PATH .","title":"1. Download and install OpenSSL for Windows."},{"location":"getting-started/build-on-windows/#2-install-pthreads-for-windows","text":"nuget install cinegy.pthreads-win64 -version 2.9.1.17 -OutputDirectory C:\\pthread-win32","title":"2. Install Pthreads for Windows"},{"location":"getting-started/build-on-windows/#3-install-cmake-for-windows","text":"CMake dowload page . The CMake GUI will help you configure the project.","title":"3. Install cmake for Windows."},{"location":"getting-started/build-on-windows/#4-generate-visual-studio-solution","text":"Assuming you are currently in the cloned repo. mkdir _build & cd _build cmake ../ -G\"Visual Studio 16 2019\" -A x64 -DPTHREAD_INCLUDE_DIR=\"C:\\pthread-win32\\cinegy.pthreads-win64.2.9.1.17\\sources\" -DPTHREAD_LIBRARY=\"C:\\pthread-win32\\cinegy.pthreads-win64.2.9.1.17\\runtimes\\win-x64\\native\\release\\pthread_lib.lib\" cmake --build ./ --config Release CMake will try to find OpenSSL and pthreads. If any of the is not found, you can define the following variables to help CMake find them: OPENSSL_ROOT_DIR=<path to OpenSSL installation> OPENSSL_LIBRARIES=<path to all the openssl libraries to link> OPENSSL_INCLUDE_DIR=<path to the OpenSSL include dir> PTHREAD_INCLUDE_DIR=<path to where pthread.h lies> PTHREAD_LIBRARY=<path to pthread.lib>","title":"4. Generate Visual Studio Solution."},{"location":"getting-started/build-on-windows/#using-vcpkg","text":"","title":"Using vcpkg"},{"location":"getting-started/vcpkg-library-manager/","text":"Vcpkg Library Manager vcpkg is a C++ library manager for Windows, Linux and MacOS. Consider its prerequisites before going further. The vcpkg library manager has preconfigured building procedures for OpenSSL and pthreads libraries. They can be easily built and further used as dependencies of SRT library. Note! vcpkg does not support LibreSSL or MbedTLS libraries. 1. Configure vcpkg Clone vcpkg using git, and build it. git clone https://github.com/microsoft/vcpkg.git cd vcpkg .\\bootstrap-vcpkg.bat The current working directory will further be referenced as VCPKG_ROOT . set VCPKG_ROOT=%cd% 2. Build SRT There are two options to build SRT using vcpkg : by vcpkg itself (Section 2.1) or use vcpkg to build openssl and pthreads , and then build SRT from sources (Section 2.2). The second case makes it possible to build the latest SRT version, while the first case builds only the version included in vcpkg . 2.1. Build with vcpkg SRT is included in vcpkg ( PR 8712 ). Therefore, Vcpkg can build it with a single command. vcpkg install libsrt 2.2. Build SRT from sources 2.2.1. Build openssl and pthreads Then build openssl and pthreads libraries using x64 toolset: vcpkg install pthreads --triplet x64-windows vcpkg install openssl --triplet x64-windows The next step is to integrate vcpkg with the build system, so that CMake can locate openssl and pthreads libraries. vcpkg integrate install 2.2.2. Build SRT library Clone the source code of srt . git clone https://github.com/Haivision/srt.git srt The current working directory will further be referenced as SRT_ROOT . set SRT_ROOT=%cd% From the srt cloned folder SRT_ROOT run cmake to generate build configuration files. cd %SRT_ROOT% md _build && cd _build cmake ../ -G \"Visual Studio 16 2019\" -A x64 -DCMAKE_TOOLCHAIN_FILE=%VCPKG_ROOT%\\scripts\\buildsystems\\vcpkg.cmake where SRT_ROOT and VCPKG_ROOT were defined above. To build the project go to %SRT_ROOT%\\_build and run: cmake --build ./ --config Release Alternatively Visual Studio IDE can be used by opening the generated solution file SRT.sln in the _build folder.","title":"Vcpkg Library Manager"},{"location":"getting-started/vcpkg-library-manager/#vcpkg-library-manager","text":"vcpkg is a C++ library manager for Windows, Linux and MacOS. Consider its prerequisites before going further. The vcpkg library manager has preconfigured building procedures for OpenSSL and pthreads libraries. They can be easily built and further used as dependencies of SRT library. Note! vcpkg does not support LibreSSL or MbedTLS libraries.","title":"Vcpkg Library Manager"},{"location":"getting-started/vcpkg-library-manager/#1-configure-vcpkg","text":"Clone vcpkg using git, and build it. git clone https://github.com/microsoft/vcpkg.git cd vcpkg .\\bootstrap-vcpkg.bat The current working directory will further be referenced as VCPKG_ROOT . set VCPKG_ROOT=%cd%","title":"1. Configure vcpkg"},{"location":"getting-started/vcpkg-library-manager/#2-build-srt","text":"There are two options to build SRT using vcpkg : by vcpkg itself (Section 2.1) or use vcpkg to build openssl and pthreads , and then build SRT from sources (Section 2.2). The second case makes it possible to build the latest SRT version, while the first case builds only the version included in vcpkg .","title":"2. Build SRT"},{"location":"getting-started/vcpkg-library-manager/#21-build-with-vcpkg","text":"SRT is included in vcpkg ( PR 8712 ). Therefore, Vcpkg can build it with a single command. vcpkg install libsrt","title":"2.1. Build with vcpkg"},{"location":"getting-started/vcpkg-library-manager/#22-build-srt-from-sources","text":"","title":"2.2. Build SRT from sources"},{"location":"getting-started/vcpkg-library-manager/#221-build-openssl-and-pthreads","text":"Then build openssl and pthreads libraries using x64 toolset: vcpkg install pthreads --triplet x64-windows vcpkg install openssl --triplet x64-windows The next step is to integrate vcpkg with the build system, so that CMake can locate openssl and pthreads libraries. vcpkg integrate install","title":"2.2.1. Build openssl and pthreads"},{"location":"getting-started/vcpkg-library-manager/#222-build-srt-library","text":"Clone the source code of srt . git clone https://github.com/Haivision/srt.git srt The current working directory will further be referenced as SRT_ROOT . set SRT_ROOT=%cd% From the srt cloned folder SRT_ROOT run cmake to generate build configuration files. cd %SRT_ROOT% md _build && cd _build cmake ../ -G \"Visual Studio 16 2019\" -A x64 -DCMAKE_TOOLCHAIN_FILE=%VCPKG_ROOT%\\scripts\\buildsystems\\vcpkg.cmake where SRT_ROOT and VCPKG_ROOT were defined above. To build the project go to %SRT_ROOT%\\_build and run: cmake --build ./ --config Release Alternatively Visual Studio IDE can be used by opening the generated solution file SRT.sln in the _build folder.","title":"2.2.2. Build SRT library"},{"location":"how-to-articles/how-to-setup-Azure-VM/","text":"How to Setup Virtual Machine in Azure Create virtual machine specifying parameters listed below Image: Ubuntu Server 18.04 LTS, or alternative Size: Standard D4s v3 (4 vcpus, 16 GiB memory), or alternative Username SSH public key Open UDP ports required for SRT transmission. Once the virtual machine is created, it's important to setup a networking rule in order to open UDP ports required for SRT transmission. Go to Settings \u2192 Networking \u2192 Add inbound port rule and specify the ports to be opened in Destination port ranges field, e.g., 4200.","title":"How to Setup Virtual Machine in Azure"},{"location":"how-to-articles/how-to-setup-Azure-VM/#how-to-setup-virtual-machine-in-azure","text":"Create virtual machine specifying parameters listed below Image: Ubuntu Server 18.04 LTS, or alternative Size: Standard D4s v3 (4 vcpus, 16 GiB memory), or alternative Username SSH public key Open UDP ports required for SRT transmission. Once the virtual machine is created, it's important to setup a networking rule in order to open UDP ports required for SRT transmission. Go to Settings \u2192 Networking \u2192 Add inbound port rule and specify the ports to be opened in Destination port ranges field, e.g., 4200.","title":"How to Setup Virtual Machine in Azure"},{"location":"how-to-articles/how-to-work-with-ssh-keys/","text":"How to Work with SSH Keys SSH keys can be used to automate access to servers. They are commonly used in scripts, backup systems, configuration management tools, and by developers and sysadmins. They also provide single sign-on, allowing the user to move between his/her accounts without having to type a password every time. This works even across organizational boundaries, and is highly convenient. For more details, please read the following article . Generating SSH Key and Copying It to Remote Server 1. Check for existing SSH key pair or generate a new one on your local machine Enter ls -al ~/.ssh to see if existing SSH keys are present: ls -al ~/.ssh # Lists the files in your .ssh directory, if they exist If you don't have an existing public and private key pair, or don't wish to use any that are available to connect to remote server, then generate a new SSH key : ssh-keygen -f ~/.ssh/mykey -t rsa -b 4096 This generates a public/private rsa key pair. The algorithm is selected using the -t option and key size using the -b option. The filename is specified using the -f <filename> option. Then you will be promted to enter a passphrase. The passphrase is used for encrypting the key, so that it cannot be used even if someone obtains the private key file. The passphrase should be cryptographically strong. The online random password generator is one possible tool for generating strong passphrases. 2. Copy the public key to the remote server To use public key authentication, the public key must be copied to a server and installed in an authorized_keys file. This can be conveniently done using the ssh-copy-id tool. Like this: ssh-copy-id -i ~/.ssh/mykey user@host Once the public key has been configured on the server, the server will allow any connecting user that has the private key to log in. During the login process, the client proves possession of the private key by digitally signing the key exchange. The copying may ask for a password or other authentication for the server. It's important to note that only the public key is copied to the server. The private one should never be copied to remote machine. Now try logging into the server with ssh user@host and check to make sure that only the key you wanted was added: cat ~/.ssh/authorized_keys 3. Test the new key Try logging into the server with ssh -i ~/.ssh/mykey user@host The login should now complete without asking for a password. Note, however, that the command might ask for the passphrase you've specified for the key. Adding the Key to SSH Agent ssh-agent is a program that can hold a user's private key, so that the private key passphrase only needs to be supplied once. A connection to the agent can also be forwarded when logging into a server, allowing SSH commands on the server to use the agent running on the user's desktop. For more information on using and configuring the SSH agent, see the ssh-agent page. The detailed instructions of running ssh-agent on macOS/Windows/Linux can be found in the following GitHub Help page . macOS When adding your SSH key to the agent, use the default macOS ssh-add command, and not an application installed by macports , homebrew , or some other external source. 1. Start the ssh-agent in the Background $ eval \"$(ssh-agent -s)\" > Agent pid 59566 2. Modify the ~/.ssh/config File If you're using macOS Sierra 10.12.2 or later, you will need to modify your ~/.ssh/config file to automatically load keys into the ssh-agent and store passphrases in your keychain Host * AddKeysToAgent yes UseKeychain yes IdentityFile ~/.ssh/mykey 3. Store the Passphrase in the Keychain Add your SSH private key to the ssh-agent and store your passphrase in the keychain $ ssh-add -K ~/.ssh/mykey Note: The -K option is Apple's standard version of ssh-add , which stores the passphrase in your keychain for you when you add an ssh key to the ssh-agent. If you don't have Apple's standard version installed, you may receive an error. For more information on resolving this error, see \"Error: ssh-add: illegal option -- K.\" Windows Please visit the following GitHub Help page for the detailed instructions of running ssh-agent on Windows. Linux 1. Start the ssh-agent in the background $ eval \"$(ssh-agent -s)\" > Agent pid 59566 2. Add your SSH private key to the ssh-agent $ ssh-add ~/.ssh/mykey Automation It is possible to turn off password authentication when SSH to a remote server using one of the following options -o PasswordAuth=no -o BatchMode=yes It is recommended to use -o BatchMode=yes option to disable any kind of prompt. In this case the script will immediately die if ssh-agent has not been started manually before running the script. In case of running the script within CI (TeamCity, etc.), it is recommended to use public SSH key without passphrase.","title":"How to Work with SSH Keys"},{"location":"how-to-articles/how-to-work-with-ssh-keys/#how-to-work-with-ssh-keys","text":"SSH keys can be used to automate access to servers. They are commonly used in scripts, backup systems, configuration management tools, and by developers and sysadmins. They also provide single sign-on, allowing the user to move between his/her accounts without having to type a password every time. This works even across organizational boundaries, and is highly convenient. For more details, please read the following article .","title":"How to Work with SSH Keys"},{"location":"how-to-articles/how-to-work-with-ssh-keys/#generating-ssh-key-and-copying-it-to-remote-server","text":"","title":"Generating SSH Key and Copying It to Remote Server"},{"location":"how-to-articles/how-to-work-with-ssh-keys/#1-check-for-existing-ssh-key-pair-or-generate-a-new-one-on-your-local-machine","text":"Enter ls -al ~/.ssh to see if existing SSH keys are present: ls -al ~/.ssh # Lists the files in your .ssh directory, if they exist If you don't have an existing public and private key pair, or don't wish to use any that are available to connect to remote server, then generate a new SSH key : ssh-keygen -f ~/.ssh/mykey -t rsa -b 4096 This generates a public/private rsa key pair. The algorithm is selected using the -t option and key size using the -b option. The filename is specified using the -f <filename> option. Then you will be promted to enter a passphrase. The passphrase is used for encrypting the key, so that it cannot be used even if someone obtains the private key file. The passphrase should be cryptographically strong. The online random password generator is one possible tool for generating strong passphrases.","title":"1. Check for existing SSH key pair or generate a new one on your local machine"},{"location":"how-to-articles/how-to-work-with-ssh-keys/#2-copy-the-public-key-to-the-remote-server","text":"To use public key authentication, the public key must be copied to a server and installed in an authorized_keys file. This can be conveniently done using the ssh-copy-id tool. Like this: ssh-copy-id -i ~/.ssh/mykey user@host Once the public key has been configured on the server, the server will allow any connecting user that has the private key to log in. During the login process, the client proves possession of the private key by digitally signing the key exchange. The copying may ask for a password or other authentication for the server. It's important to note that only the public key is copied to the server. The private one should never be copied to remote machine. Now try logging into the server with ssh user@host and check to make sure that only the key you wanted was added: cat ~/.ssh/authorized_keys","title":"2. Copy the public key to the remote server"},{"location":"how-to-articles/how-to-work-with-ssh-keys/#3-test-the-new-key","text":"Try logging into the server with ssh -i ~/.ssh/mykey user@host The login should now complete without asking for a password. Note, however, that the command might ask for the passphrase you've specified for the key.","title":"3. Test the new key"},{"location":"how-to-articles/how-to-work-with-ssh-keys/#adding-the-key-to-ssh-agent","text":"ssh-agent is a program that can hold a user's private key, so that the private key passphrase only needs to be supplied once. A connection to the agent can also be forwarded when logging into a server, allowing SSH commands on the server to use the agent running on the user's desktop. For more information on using and configuring the SSH agent, see the ssh-agent page. The detailed instructions of running ssh-agent on macOS/Windows/Linux can be found in the following GitHub Help page .","title":"Adding the Key to SSH Agent"},{"location":"how-to-articles/how-to-work-with-ssh-keys/#macos","text":"When adding your SSH key to the agent, use the default macOS ssh-add command, and not an application installed by macports , homebrew , or some other external source.","title":"macOS"},{"location":"how-to-articles/how-to-work-with-ssh-keys/#1-start-the-ssh-agent-in-the-background","text":"$ eval \"$(ssh-agent -s)\" > Agent pid 59566","title":"1. Start the ssh-agent in the Background"},{"location":"how-to-articles/how-to-work-with-ssh-keys/#2-modify-the-sshconfig-file","text":"If you're using macOS Sierra 10.12.2 or later, you will need to modify your ~/.ssh/config file to automatically load keys into the ssh-agent and store passphrases in your keychain Host * AddKeysToAgent yes UseKeychain yes IdentityFile ~/.ssh/mykey","title":"2. Modify the ~/.ssh/config File"},{"location":"how-to-articles/how-to-work-with-ssh-keys/#3-store-the-passphrase-in-the-keychain","text":"Add your SSH private key to the ssh-agent and store your passphrase in the keychain $ ssh-add -K ~/.ssh/mykey Note: The -K option is Apple's standard version of ssh-add , which stores the passphrase in your keychain for you when you add an ssh key to the ssh-agent. If you don't have Apple's standard version installed, you may receive an error. For more information on resolving this error, see \"Error: ssh-add: illegal option -- K.\"","title":"3. Store the Passphrase in the Keychain"},{"location":"how-to-articles/how-to-work-with-ssh-keys/#windows","text":"Please visit the following GitHub Help page for the detailed instructions of running ssh-agent on Windows.","title":"Windows"},{"location":"how-to-articles/how-to-work-with-ssh-keys/#linux","text":"","title":"Linux"},{"location":"how-to-articles/how-to-work-with-ssh-keys/#1-start-the-ssh-agent-in-the-background_1","text":"$ eval \"$(ssh-agent -s)\" > Agent pid 59566","title":"1. Start the ssh-agent in the background"},{"location":"how-to-articles/how-to-work-with-ssh-keys/#2-add-your-ssh-private-key-to-the-ssh-agent","text":"$ ssh-add ~/.ssh/mykey","title":"2. Add your SSH private key to the ssh-agent"},{"location":"how-to-articles/how-to-work-with-ssh-keys/#automation","text":"It is possible to turn off password authentication when SSH to a remote server using one of the following options -o PasswordAuth=no -o BatchMode=yes It is recommended to use -o BatchMode=yes option to disable any kind of prompt. In this case the script will immediately die if ssh-agent has not been started manually before running the script. In case of running the script within CI (TeamCity, etc.), it is recommended to use public SSH key without passphrase.","title":"Automation"},{"location":"how-to-articles/using-netem-to-emulate-networks/","text":"Using NetEm to Emulate Networks NetEm (Network Emulator) is an enhancement of the Linux traffic control facilities that allow adding delay, packet loss, duplication and other characteristics to packets outgoing from a selected network interface. NetEm uses the existing Quality Of Service (QOS) and Differentiated Services (diffserv) facilities in the Linux kernel. It's a great tool to test SRT connections with network impairments like on real networks. Installation Linux traffic control (tc) and NetEm (netem) are available in most Linux distributions, typically as part of the iproute2 package. On Ubuntu systems the iproute2 package (including netem) can be installed using following command: sudo apt-get install iproute2 Installation on CentOS 8.2 On CentOS 8.2 the iproute-tc package (including netem) can be installed using following command: sudo yum install iproute-tc NOTE : RHEL-based systems like CentOS 8.2 might need an additional kernel module in order to run netem. This would be indicated if, in running netem, the look-up of the name for qdisc fails, like in example shown below: sudo tc qdisc add dev enp7s0 root netem delay 10ms 10ms loss 2% rate 12mbit Error: Specified qdisc not found. In such a case, install the modules kernel-modules-extra and kernel-debug-modules-extra with following command: sudo yum install kernel-debug-modules-extra kernel-modules-extra After installation a reboot is needed to activate the kernel modules. Getting Started with TC & NetEm The following examples use the interface enp7s0 . Modify to match your network adapter (e.g. eth0 ). To be able to change settings, root privileges are required. Adding Delay NOTE : netem only adds delay to packets leaving the interface. If you want to simulate bi-directional delay, two instances of tc netem - one on each end - are required. The following command adds 250 ms of delay to packets leaving interface enp7s0 : sudo tc qdisc add dev enp7s0 root netem delay 250ms Adding Delay with Volatility The following command sets the transmission of enp7s0 network interface to be delayed by 100ms + 10ms (any value between 90 and 110 ms): sudp tc qdisc add dev enp7s0 root netem delay 100ms 10ms The volatility (randomness) of such fluctuations can be further specified. The following command sets network interface enp7s0 transmission to 100 ms, while 30% of the packets selected at random are delayed by +10 ms: sudo tc qdisc add dev enp7s0 root netem delay 100ms 10ms 30% Adding Packet Loss The following command sets the enp7s0 network interface transmission to randomly drop 1% of the packets: sudo tc qdisc add dev enp7s0 root netem loss 1% Adding Packet Loss with Success Rate sudo tc qdisc add dev enp7s0 root netem loss 1% 30% Duplicated Packets sudo tc qdisc add dev enp7s0 root netem duplicate 1% Corrupted Packets For Linux kernel versions above 2.6.16, netem can also simulate damage to packets. The following command randomly damages 0.2% of the outgoing packets: sudo tc qdisc add dev enp7s0 root netem corrupt 0.2% Packet Reordering The following command sets network interface enp7s0 to send out 25% of data packets (with 50% relevance) immediately and delay all other packets by 10 ms. sudo tc qdisc add dev enp7s0 root netem delay 10ms reorder 25% 50% View the Configured Network Conditions sudo tc qdisc show dev enp7s0 Stopping Network Impairments IMPORTANT : Please remember to disable the network impairments after tests are done by using the following command: sudo tc qdisc del dev enp7s0 root netem The above command will delete the root configuration that was used in the examples above. NetEm Wrapper We provide a netem wrapper written in Python to concatenate network conditions by means of simple configuration files. Here is an example of a config file that can be created with it: { \"name\": \"example\", \"interface\": \"wlp3s0\", \"events\": { \"1\": { \"duration\": 5000, \"rules\": [ \"clear\" ] }, \"2\": { \"duration\": 15000, \"rules\": [ \"delay 30ms 10ms distribution normal\", \"loss 0.1% 0.25%\" ] }, \"3\": { \"duration\": 10000, \"rules\": [ \"delay 50ms\" ] }, \"4\": { \"duration\": 5000, \"rules\": [ \"clear\" ] } } } The wrapper has an optional parameter that outputs a json file with the timestamps of when the conditions were applied. It can be useful in case the time of changing the network impairments is required for further analysis. Further Reading These were just some basic examples to get started. TC & NetEm allow complex simulations and more information can be found in the documents listed below: Emulating WAN with NETEM II: Packet Loss, Duplication, Reordering, and Corruption (PDF by University of South Carolina) Traffic Control Manual (PDF by University of New Mexico)","title":"Using NetEm to Emulate Networks"},{"location":"how-to-articles/using-netem-to-emulate-networks/#using-netem-to-emulate-networks","text":"NetEm (Network Emulator) is an enhancement of the Linux traffic control facilities that allow adding delay, packet loss, duplication and other characteristics to packets outgoing from a selected network interface. NetEm uses the existing Quality Of Service (QOS) and Differentiated Services (diffserv) facilities in the Linux kernel. It's a great tool to test SRT connections with network impairments like on real networks.","title":"Using NetEm to Emulate Networks"},{"location":"how-to-articles/using-netem-to-emulate-networks/#installation","text":"Linux traffic control (tc) and NetEm (netem) are available in most Linux distributions, typically as part of the iproute2 package. On Ubuntu systems the iproute2 package (including netem) can be installed using following command: sudo apt-get install iproute2","title":"Installation"},{"location":"how-to-articles/using-netem-to-emulate-networks/#installation-on-centos-82","text":"On CentOS 8.2 the iproute-tc package (including netem) can be installed using following command: sudo yum install iproute-tc NOTE : RHEL-based systems like CentOS 8.2 might need an additional kernel module in order to run netem. This would be indicated if, in running netem, the look-up of the name for qdisc fails, like in example shown below: sudo tc qdisc add dev enp7s0 root netem delay 10ms 10ms loss 2% rate 12mbit Error: Specified qdisc not found. In such a case, install the modules kernel-modules-extra and kernel-debug-modules-extra with following command: sudo yum install kernel-debug-modules-extra kernel-modules-extra After installation a reboot is needed to activate the kernel modules.","title":"Installation on CentOS 8.2"},{"location":"how-to-articles/using-netem-to-emulate-networks/#getting-started-with-tc-netem","text":"The following examples use the interface enp7s0 . Modify to match your network adapter (e.g. eth0 ). To be able to change settings, root privileges are required.","title":"Getting Started with TC &amp; NetEm"},{"location":"how-to-articles/using-netem-to-emulate-networks/#adding-delay","text":"NOTE : netem only adds delay to packets leaving the interface. If you want to simulate bi-directional delay, two instances of tc netem - one on each end - are required. The following command adds 250 ms of delay to packets leaving interface enp7s0 : sudo tc qdisc add dev enp7s0 root netem delay 250ms","title":"Adding Delay"},{"location":"how-to-articles/using-netem-to-emulate-networks/#adding-delay-with-volatility","text":"The following command sets the transmission of enp7s0 network interface to be delayed by 100ms + 10ms (any value between 90 and 110 ms): sudp tc qdisc add dev enp7s0 root netem delay 100ms 10ms The volatility (randomness) of such fluctuations can be further specified. The following command sets network interface enp7s0 transmission to 100 ms, while 30% of the packets selected at random are delayed by +10 ms: sudo tc qdisc add dev enp7s0 root netem delay 100ms 10ms 30%","title":"Adding Delay with Volatility"},{"location":"how-to-articles/using-netem-to-emulate-networks/#adding-packet-loss","text":"The following command sets the enp7s0 network interface transmission to randomly drop 1% of the packets: sudo tc qdisc add dev enp7s0 root netem loss 1%","title":"Adding Packet Loss"},{"location":"how-to-articles/using-netem-to-emulate-networks/#adding-packet-loss-with-success-rate","text":"sudo tc qdisc add dev enp7s0 root netem loss 1% 30%","title":"Adding Packet Loss with Success Rate"},{"location":"how-to-articles/using-netem-to-emulate-networks/#duplicated-packets","text":"sudo tc qdisc add dev enp7s0 root netem duplicate 1%","title":"Duplicated Packets"},{"location":"how-to-articles/using-netem-to-emulate-networks/#corrupted-packets","text":"For Linux kernel versions above 2.6.16, netem can also simulate damage to packets. The following command randomly damages 0.2% of the outgoing packets: sudo tc qdisc add dev enp7s0 root netem corrupt 0.2%","title":"Corrupted Packets"},{"location":"how-to-articles/using-netem-to-emulate-networks/#packet-reordering","text":"The following command sets network interface enp7s0 to send out 25% of data packets (with 50% relevance) immediately and delay all other packets by 10 ms. sudo tc qdisc add dev enp7s0 root netem delay 10ms reorder 25% 50%","title":"Packet Reordering"},{"location":"how-to-articles/using-netem-to-emulate-networks/#view-the-configured-network-conditions","text":"sudo tc qdisc show dev enp7s0","title":"View the Configured Network Conditions"},{"location":"how-to-articles/using-netem-to-emulate-networks/#stopping-network-impairments","text":"IMPORTANT : Please remember to disable the network impairments after tests are done by using the following command: sudo tc qdisc del dev enp7s0 root netem The above command will delete the root configuration that was used in the examples above.","title":"Stopping Network Impairments"},{"location":"how-to-articles/using-netem-to-emulate-networks/#netem-wrapper","text":"We provide a netem wrapper written in Python to concatenate network conditions by means of simple configuration files. Here is an example of a config file that can be created with it: { \"name\": \"example\", \"interface\": \"wlp3s0\", \"events\": { \"1\": { \"duration\": 5000, \"rules\": [ \"clear\" ] }, \"2\": { \"duration\": 15000, \"rules\": [ \"delay 30ms 10ms distribution normal\", \"loss 0.1% 0.25%\" ] }, \"3\": { \"duration\": 10000, \"rules\": [ \"delay 50ms\" ] }, \"4\": { \"duration\": 5000, \"rules\": [ \"clear\" ] } } } The wrapper has an optional parameter that outputs a json file with the timestamps of when the conditions were applied. It can be useful in case the time of changing the network impairments is required for further analysis.","title":"NetEm Wrapper"},{"location":"how-to-articles/using-netem-to-emulate-networks/#further-reading","text":"These were just some basic examples to get started. TC & NetEm allow complex simulations and more information can be found in the documents listed below: Emulating WAN with NETEM II: Packet Loss, Duplication, Reordering, and Corruption (PDF by University of South Carolina) Traffic Control Manual (PDF by University of New Mexico)","title":"Further Reading"},{"location":"how-to-articles/using-tshark-wireshark-to-analyse-srt-traffic/","text":"Using TShark & Wireshark to Analyse SRT Traffic Wireshark is a free and open-source packet analyzer. It is a very powerful tools to analyse network traffic, such as a connection. Since version 3.0 Wireshark supports the SRT protocol and display filters can be applied to find particular elements of a SRT stream easily TShark is a terminal oriented version of Wireshark designed for capturing and displaying packets when an interactive user interface isn't necessary or available. Both tools - TShark and Wireshark with GUI - can be used to create packet captures, which are helpful to reproduce errors remotely or to feed other analysis tools such as lib-tcpdump-processing . If you only want to capture files and do the analysis on a remote machine, installation of TShark is sufficient. Installation Installing TShark & Wireshark on CentOS TShark on CentOS is part of the CLI-version of Wireshark. To install use following command: sudo yum install wireshark This will install tshark in /usr/sbin/tshark To install Wireshark with GUI, do the following: sudo yum install wireshark-gnome Installing TShark & Wireshark on Ubuntu 18.04 LTS Ubuntu 18.04 only provides Wireshark version 2.6, which has no native SRT support. To install the desired 3.0 or higher version, you could either build Wireshark yourself or follow the instructions from launchpad to get a binary package. Basically you would add a Personal Package Archive (PPA) to your package repository with following 3 commands. For detailed instructions check the launchpad page at link above. sudo add-apt-repository ppa:wireshark-dev/stable sudo apt-get update sudo apt install wireshark tshark To install the GUI version of Wireshark use following command after adding the PPA: sudo apt-get install wireshark-qt Installing TShark & Wireshark on Ubuntu 19+ Recent versions of Ubuntu serve version 3+ versions of TShark & Wireshark. sudo apt-get update sudo apt install wireshark tshark To install the GUI version of Wireshark use following command: sudo apt-get install wireshark-qt Installing TShark & Wireshark on MacOS and Windows Please download the Wireshark installer for MacOS or Windows directly from the Wireshark download site and follow the instructions of the installer. TShark installation can be optionally selected (default is on). Using TShark to capture network traffic In order to get best results for further analysis, the network capture should be started before the SRT connection is initiated. So we capture the SRT handshake as well, which can be useful later on. Linux & MacOS Let's assume you are receiving a SRT stream on UDP port 4200 and want to capture it. First you want to make sure, that you are capturing the traffic on the right interface. If your system has multiple network interfaces you could use following command to list all available interfaces: (depending on your settings, you might need root privileges, which can be granted with sudo command) Most Linux systems: sudo ip a MacOS and some Linux systems: sudo ifconfig Once you have identified the interface of your choice run following command: (some systems might need root priviliges to execute packet captures. Use sudo command then) tshark -i enp9s0 -f \"udp port 4200\" -s 1500 -w ./rcv-SRT.pcapng -i enp9s0 specifies the interface. Depending on your system this could also be -i eth0 or -i eno1 or whatever the particular interface is named like -f \"udp port 4200\" specifies a filter rule to only capture UDP packets on port 4200 -s 1500 defines the snapshot length to capture, in this case 1500 bytes per packet -w ./rcv-SRT.pcapng sets the path and filename in which the captured data is written. In this case in the same directory that you are currently in with the file name rcv-SRT.pcapng Windows The procedure on Windows is quite similar, however the naming conventions for the network adapters can be a confusing. With following command you can found out IP addresses of your network interfaces: ipconfig /all Note down the name of the Ethernet adapter of your choice with the correct IP address that you were looking for. In this example we are looking at Ethernet adapter Local Area Connection 2: Now point your shell (Terminal / PowerShell) to the Wireshark directory, which is per default: c:\\Program Files\\Wireshark and execute following command: tshark.exe -D The option -D lists all interfaces, unfortunately without IP address. But we already identified the IP with the ipconfig command in the prior step. The output would give you something like this: c:\\Program Files\\Wireshark>tshark.exe -D 1. \\Device\\NPF_{C4423365-7B46-493C-95E8-2F009A099E0A} (VMware Network Adapter VMnet8) 2. \\Device\\NPF_{78032B7E-4968-42D3-9F37-287EA86C0AAA} (Local Area Connection* 10) 3. \\Device\\NPF_{B9A7544E-73D8-4533-BC46-C3A2B99D68BF} (VirtualBox Host-Only Network) 4. \\Device\\NPF_NdisWanIp (NdisWan Adapter) 5. \\Device\\NPF_{A0B05D56-015A-4045-832F-E244BC32F9DC} (Local Area Connection) 6. \\Device\\NPF_NdisWanBh (NdisWan Adapter) 7. \\Device\\NPF_NdisWanIpv6 (NdisWan Adapter) 8. \\Device\\NPF_{03564282-7495-4FB5-98A2-CF349E10BE23} (Local Area Connection 2) 9. \\Device\\NPF_{663F8BBF-7C41-494B-B2BA-269DA97B8B49} (VMware Network Adapter VMnet1) 10. \\Device\\NPF_{3556DA2E-DEC6-410B-B791-E82CC8ABF216} (Local Area Connection 10) 11. \\Device\\NPF_Loopback (Adapter for loopback traffic capture) 12. \\Device\\NPF_{1949D5F2-F562-4C4E-8665-EABC55BFBFFC} (Local Area Connection 4) 13. \\Device\\NPF_{F4A0A87F-5DB3-42E5-A29E-C061045C1E99} (Local Area Connection 11) The adapter of our choice in this example ( Ethernet adapter Local Area Connection 2 ) has the ID 8 . Finally we can use the ID 8 to perform the network capture by issuing following command: tshark.exe -i 8 -f \"udp port 4200\" -s 1500 -w c:\\temp\\rcv-SRT.pcapng Best practice tips start the capture before starting the SRT transmission name the .pcapng files in a way, which gives you a clue later on. For example use rcv or snd in filename and maybe something like testrun-1 or other identifiers, which help to understand what you did later on on Linux and MacOS you can specify a particular length of time to run the capture with help of timeout command. For example use following command to capture 30 seconds of traffic sudo timeout 30 tshark -i enp9s0 -f \"udp port 4900\" -s 1500 -w ./rcv-SRT.pcapng to stop a capture without timeout given just use the keyboard command CTRL + C timeout on Windows works a bit different. To perform a 30 second capture you can use: start \"\" app.exe & timeout /t 30 & taskkill /im app.exe /f for our example this would result in: start \"\" tshark.exe -i 8 -f \"udp port 4200\" -s 1500 -w c:\\temp\\rcv-SRT.pcapng & timeout 30 & taskkill /im tshark.exe /f Analysing the .pcapng capture file lib-tcpdump-processing Specifically for network captures of SRT streams you can use the python scripts out of the library lib-tcpdump-processing provided by Maria Sharabayko. It's a great set of tools to analyse details of an SRT stream and get details quickly. Example output of the get-traffic-stats script: Overall UDP rate: 7.501 Mbps SRT Data org+rexmit pld: 7.367 Mbps SRT Data org payload: 6.665 Mbps SRT Data overhead: 1.824% SRT Data missing: 0.000% SRT Data rexmit overhead: 10.723% SRT ACK overhead: 0.286% SRT ACKACK overhead: 0.286% SRT NAK overhead: 0.162% =========================================== SRT overall overhead: 11.325% SRT Data packets (org): 19913 SRT retransmitted: 719 packets (2097 retransmissions) SRT DATA retransmisions: 10.531% \u00d7 DATA packets SRT retransmitted: 3.611% of original packets including retransmitted: once: 0.015% of original packets twice: 0.291% of original packets 3\u00d7: 3.284% of original packets 4\u00d7: 0.020% of original packets more: 0.000% of original packets For further documentation and examples please visit the website: lib-tcpdump-processing Wireshark GUI Before you can get started with analysing SRT in the Wireshark GUI, you need to uncheck interpretation of UDT packets in Wireshark. To do that, click on Analyse in the menu bar on top and select Enabled Protocols from the dropdown menu. (keyboard shortcut: CTRL+SHIFT+E ). Now search for UDT and uncheck the UDT-options which are displayed like shown in picture below. Now you can import your captured .pcapng file or start a live capture from inside the Wireshark GUI. A list of possible \"display filters\" for the SRT protocol can be found at the Wireshark SRT Display Filter Reference page . There are cases when Wireshark will not pass the remainder of the UDP packet to sub-dissectors. SRT is a sub-dissector of UDP. This case is in the decode_udp_ports function of Wireshark, and has the following comment description: Do lookups with the subdissector table. We try the port number with the lower value first, followed by the port number with the higher value. This means that, for packets where a dissector is registered for both port numbers: 1) we pick the same dissector for traffic going in both directions; 2) we prefer the port number that's more likely to be the right one (as that prefers well-known ports to reserved ports); although there is, of course, no guarantee that any such strategy will always pick the right port number. XXX - we ignore port numbers of 0, as some dissectors use a port number of 0 to disable the port, and as RFC 768 says that the source port in UDP datagrams is optional and is 0 if not used. :exclamation: Wireshark offers a workaround for this. You have to set the following advanced option: Edit -> Preferences -> Advanced: udp.try_heuristic_first = TRUE . This will make a UDP packet to be passes to sub-dissectors first.","title":"Using TShark & Wireshark to Analyse SRT Traffic"},{"location":"how-to-articles/using-tshark-wireshark-to-analyse-srt-traffic/#using-tshark-wireshark-to-analyse-srt-traffic","text":"Wireshark is a free and open-source packet analyzer. It is a very powerful tools to analyse network traffic, such as a connection. Since version 3.0 Wireshark supports the SRT protocol and display filters can be applied to find particular elements of a SRT stream easily TShark is a terminal oriented version of Wireshark designed for capturing and displaying packets when an interactive user interface isn't necessary or available. Both tools - TShark and Wireshark with GUI - can be used to create packet captures, which are helpful to reproduce errors remotely or to feed other analysis tools such as lib-tcpdump-processing . If you only want to capture files and do the analysis on a remote machine, installation of TShark is sufficient.","title":"Using TShark &amp; Wireshark to Analyse SRT Traffic"},{"location":"how-to-articles/using-tshark-wireshark-to-analyse-srt-traffic/#installation","text":"","title":"Installation"},{"location":"how-to-articles/using-tshark-wireshark-to-analyse-srt-traffic/#installing-tshark-wireshark-on-centos","text":"TShark on CentOS is part of the CLI-version of Wireshark. To install use following command: sudo yum install wireshark This will install tshark in /usr/sbin/tshark To install Wireshark with GUI, do the following: sudo yum install wireshark-gnome","title":"Installing TShark &amp; Wireshark on CentOS"},{"location":"how-to-articles/using-tshark-wireshark-to-analyse-srt-traffic/#installing-tshark-wireshark-on-ubuntu-1804-lts","text":"Ubuntu 18.04 only provides Wireshark version 2.6, which has no native SRT support. To install the desired 3.0 or higher version, you could either build Wireshark yourself or follow the instructions from launchpad to get a binary package. Basically you would add a Personal Package Archive (PPA) to your package repository with following 3 commands. For detailed instructions check the launchpad page at link above. sudo add-apt-repository ppa:wireshark-dev/stable sudo apt-get update sudo apt install wireshark tshark To install the GUI version of Wireshark use following command after adding the PPA: sudo apt-get install wireshark-qt","title":"Installing TShark &amp; Wireshark on Ubuntu 18.04 LTS"},{"location":"how-to-articles/using-tshark-wireshark-to-analyse-srt-traffic/#installing-tshark-wireshark-on-ubuntu-19","text":"Recent versions of Ubuntu serve version 3+ versions of TShark & Wireshark. sudo apt-get update sudo apt install wireshark tshark To install the GUI version of Wireshark use following command: sudo apt-get install wireshark-qt","title":"Installing TShark &amp; Wireshark on Ubuntu 19+"},{"location":"how-to-articles/using-tshark-wireshark-to-analyse-srt-traffic/#installing-tshark-wireshark-on-macos-and-windows","text":"Please download the Wireshark installer for MacOS or Windows directly from the Wireshark download site and follow the instructions of the installer. TShark installation can be optionally selected (default is on).","title":"Installing TShark &amp; Wireshark on MacOS and Windows"},{"location":"how-to-articles/using-tshark-wireshark-to-analyse-srt-traffic/#using-tshark-to-capture-network-traffic","text":"In order to get best results for further analysis, the network capture should be started before the SRT connection is initiated. So we capture the SRT handshake as well, which can be useful later on.","title":"Using TShark to capture network traffic"},{"location":"how-to-articles/using-tshark-wireshark-to-analyse-srt-traffic/#linux-macos","text":"Let's assume you are receiving a SRT stream on UDP port 4200 and want to capture it. First you want to make sure, that you are capturing the traffic on the right interface. If your system has multiple network interfaces you could use following command to list all available interfaces: (depending on your settings, you might need root privileges, which can be granted with sudo command) Most Linux systems: sudo ip a MacOS and some Linux systems: sudo ifconfig Once you have identified the interface of your choice run following command: (some systems might need root priviliges to execute packet captures. Use sudo command then) tshark -i enp9s0 -f \"udp port 4200\" -s 1500 -w ./rcv-SRT.pcapng -i enp9s0 specifies the interface. Depending on your system this could also be -i eth0 or -i eno1 or whatever the particular interface is named like -f \"udp port 4200\" specifies a filter rule to only capture UDP packets on port 4200 -s 1500 defines the snapshot length to capture, in this case 1500 bytes per packet -w ./rcv-SRT.pcapng sets the path and filename in which the captured data is written. In this case in the same directory that you are currently in with the file name rcv-SRT.pcapng","title":"Linux &amp; MacOS"},{"location":"how-to-articles/using-tshark-wireshark-to-analyse-srt-traffic/#windows","text":"The procedure on Windows is quite similar, however the naming conventions for the network adapters can be a confusing. With following command you can found out IP addresses of your network interfaces: ipconfig /all Note down the name of the Ethernet adapter of your choice with the correct IP address that you were looking for. In this example we are looking at Ethernet adapter Local Area Connection 2: Now point your shell (Terminal / PowerShell) to the Wireshark directory, which is per default: c:\\Program Files\\Wireshark and execute following command: tshark.exe -D The option -D lists all interfaces, unfortunately without IP address. But we already identified the IP with the ipconfig command in the prior step. The output would give you something like this: c:\\Program Files\\Wireshark>tshark.exe -D 1. \\Device\\NPF_{C4423365-7B46-493C-95E8-2F009A099E0A} (VMware Network Adapter VMnet8) 2. \\Device\\NPF_{78032B7E-4968-42D3-9F37-287EA86C0AAA} (Local Area Connection* 10) 3. \\Device\\NPF_{B9A7544E-73D8-4533-BC46-C3A2B99D68BF} (VirtualBox Host-Only Network) 4. \\Device\\NPF_NdisWanIp (NdisWan Adapter) 5. \\Device\\NPF_{A0B05D56-015A-4045-832F-E244BC32F9DC} (Local Area Connection) 6. \\Device\\NPF_NdisWanBh (NdisWan Adapter) 7. \\Device\\NPF_NdisWanIpv6 (NdisWan Adapter) 8. \\Device\\NPF_{03564282-7495-4FB5-98A2-CF349E10BE23} (Local Area Connection 2) 9. \\Device\\NPF_{663F8BBF-7C41-494B-B2BA-269DA97B8B49} (VMware Network Adapter VMnet1) 10. \\Device\\NPF_{3556DA2E-DEC6-410B-B791-E82CC8ABF216} (Local Area Connection 10) 11. \\Device\\NPF_Loopback (Adapter for loopback traffic capture) 12. \\Device\\NPF_{1949D5F2-F562-4C4E-8665-EABC55BFBFFC} (Local Area Connection 4) 13. \\Device\\NPF_{F4A0A87F-5DB3-42E5-A29E-C061045C1E99} (Local Area Connection 11) The adapter of our choice in this example ( Ethernet adapter Local Area Connection 2 ) has the ID 8 . Finally we can use the ID 8 to perform the network capture by issuing following command: tshark.exe -i 8 -f \"udp port 4200\" -s 1500 -w c:\\temp\\rcv-SRT.pcapng","title":"Windows"},{"location":"how-to-articles/using-tshark-wireshark-to-analyse-srt-traffic/#best-practice-tips","text":"start the capture before starting the SRT transmission name the .pcapng files in a way, which gives you a clue later on. For example use rcv or snd in filename and maybe something like testrun-1 or other identifiers, which help to understand what you did later on on Linux and MacOS you can specify a particular length of time to run the capture with help of timeout command. For example use following command to capture 30 seconds of traffic sudo timeout 30 tshark -i enp9s0 -f \"udp port 4900\" -s 1500 -w ./rcv-SRT.pcapng to stop a capture without timeout given just use the keyboard command CTRL + C timeout on Windows works a bit different. To perform a 30 second capture you can use: start \"\" app.exe & timeout /t 30 & taskkill /im app.exe /f for our example this would result in: start \"\" tshark.exe -i 8 -f \"udp port 4200\" -s 1500 -w c:\\temp\\rcv-SRT.pcapng & timeout 30 & taskkill /im tshark.exe /f","title":"Best practice tips"},{"location":"how-to-articles/using-tshark-wireshark-to-analyse-srt-traffic/#analysing-the-pcapng-capture-file","text":"","title":"Analysing the .pcapng capture file"},{"location":"how-to-articles/using-tshark-wireshark-to-analyse-srt-traffic/#lib-tcpdump-processing","text":"Specifically for network captures of SRT streams you can use the python scripts out of the library lib-tcpdump-processing provided by Maria Sharabayko. It's a great set of tools to analyse details of an SRT stream and get details quickly. Example output of the get-traffic-stats script: Overall UDP rate: 7.501 Mbps SRT Data org+rexmit pld: 7.367 Mbps SRT Data org payload: 6.665 Mbps SRT Data overhead: 1.824% SRT Data missing: 0.000% SRT Data rexmit overhead: 10.723% SRT ACK overhead: 0.286% SRT ACKACK overhead: 0.286% SRT NAK overhead: 0.162% =========================================== SRT overall overhead: 11.325% SRT Data packets (org): 19913 SRT retransmitted: 719 packets (2097 retransmissions) SRT DATA retransmisions: 10.531% \u00d7 DATA packets SRT retransmitted: 3.611% of original packets including retransmitted: once: 0.015% of original packets twice: 0.291% of original packets 3\u00d7: 3.284% of original packets 4\u00d7: 0.020% of original packets more: 0.000% of original packets For further documentation and examples please visit the website: lib-tcpdump-processing","title":"lib-tcpdump-processing"},{"location":"how-to-articles/using-tshark-wireshark-to-analyse-srt-traffic/#wireshark-gui","text":"Before you can get started with analysing SRT in the Wireshark GUI, you need to uncheck interpretation of UDT packets in Wireshark. To do that, click on Analyse in the menu bar on top and select Enabled Protocols from the dropdown menu. (keyboard shortcut: CTRL+SHIFT+E ). Now search for UDT and uncheck the UDT-options which are displayed like shown in picture below. Now you can import your captured .pcapng file or start a live capture from inside the Wireshark GUI. A list of possible \"display filters\" for the SRT protocol can be found at the Wireshark SRT Display Filter Reference page . There are cases when Wireshark will not pass the remainder of the UDP packet to sub-dissectors. SRT is a sub-dissector of UDP. This case is in the decode_udp_ports function of Wireshark, and has the following comment description: Do lookups with the subdissector table. We try the port number with the lower value first, followed by the port number with the higher value. This means that, for packets where a dissector is registered for both port numbers: 1) we pick the same dissector for traffic going in both directions; 2) we prefer the port number that's more likely to be the right one (as that prefers well-known ports to reserved ports); although there is, of course, no guarantee that any such strategy will always pick the right port number. XXX - we ignore port numbers of 0, as some dissectors use a port number of 0 to disable the port, and as RFC 768 says that the source port in UDP datagrams is optional and is 0 if not used. :exclamation: Wireshark offers a workaround for this. You have to set the following advanced option: Edit -> Preferences -> Advanced: udp.try_heuristic_first = TRUE . This will make a UDP packet to be passes to sub-dissectors first.","title":"Wireshark GUI"},{"location":"protocol/","text":"The Protocol The section contains a description of key protocol features.","title":"The Protocol"},{"location":"protocol/#the-protocol","text":"The section contains a description of key protocol features.","title":"The Protocol"},{"location":"protocol/bandwidth-estimation/","text":"Bandwidth Estimation SRT estimates the value of the link capacity. This is done by using a packet pair probing technique. In this technique, the sender sends two back-to-back packets of the same size. Once these two packets arrive at the receiver side, there will be an interval between the two packets. The link capacity can then be determined by B = packet size / interval SRT sends out a packet pair every 16 packets. However, when it happens that there is no 17th packet to be sent out, SRT will still send out the 16th packet, rather than waiting for the next one. In this case, there will be a bigger interval (hence underestimation) at the receiver side. The receiver should use a median filter to detect and discard such values. In addition, other patterns of packet pairs can be used, as long as the receiver has a way to identify the packet pairs. Ningning Hu, Peter Steenkiste. Estimating Available Bandwidth Using Packet Pair Probing . 2002. Yunhong Gu. The UDT Congestion Control Algorithm . 2009.","title":"Bandwidth Estimation"},{"location":"protocol/bandwidth-estimation/#bandwidth-estimation","text":"SRT estimates the value of the link capacity. This is done by using a packet pair probing technique. In this technique, the sender sends two back-to-back packets of the same size. Once these two packets arrive at the receiver side, there will be an interval between the two packets. The link capacity can then be determined by B = packet size / interval SRT sends out a packet pair every 16 packets. However, when it happens that there is no 17th packet to be sent out, SRT will still send out the 16th packet, rather than waiting for the next one. In this case, there will be a bigger interval (hence underestimation) at the receiver side. The receiver should use a median filter to detect and discard such values. In addition, other patterns of packet pairs can be used, as long as the receiver has a way to identify the packet pairs. Ningning Hu, Peter Steenkiste. Estimating Available Bandwidth Using Packet Pair Probing . 2002. Yunhong Gu. The UDT Congestion Control Algorithm . 2009.","title":"Bandwidth Estimation"},{"location":"protocol/configuration/","text":"SRT Configuration Calculator .p-text { --p-safari-helper1: rgb(33, 150, 243); position: relative; display: inline-block; padding-top: 6px; font-family: var(--p-font, \"Roboto\", \"Segoe UI\", BlinkMacSystemFont, system-ui, -apple-system); font-size: 16px; line-height: 1.5; overflow: hidden } .p-text > input, .p-text > textarea { box-sizing: border-box; margin: 0; border: 1px solid rgba(0, 0, 0, .6); border-top-color: transparent; border-radius: 4px; padding: 15px 13px 15px; width: 100%; height: inherit; color: rgba(0, 0, 0, .87); background-color: transparent; box-shadow: none; font-family: inherit; font-size: inherit; line-height: inherit; caret-color: #2196f3; transition: border .2s, box-shadow .2s } .p-text > input + span, .p-text > textarea + span { position: absolute; top: 0; left: 0; display: flex; border-color: rgba(0, 0, 0, .6); width: 100%; max-height: 100%; color: rgba(0, 0, 0, .6); font-size: 75%; line-height: 15px; cursor: text; transition: color .2s, font-size .2s, line-height .2s } .p-text > input + span::after, .p-text > input + span::before, .p-text > textarea + span::after, .p-text > textarea + span::before { content: \"\"; display: block; box-sizing: border-box; margin-top: 6px; border-top: solid 1px; border-top-color: rgba(0, 0, 0, .6); min-width: 10px; height: 8px; pointer-events: none; box-shadow: inset 0 1px transparent; transition: border-color .2s, box-shadow .2s } .p-text > input + span::before, .p-text > textarea + span::before { margin-right: 4px; border-left: solid 1px transparent; border-radius: 4px 0 } .p-text > input + span::after, .p-text > textarea + span::after { flex-grow: 1; margin-left: 4px; border-right: solid 1px transparent; border-radius: 0 4px } .p-text:hover > input, .p-text:hover > textarea { border-color: rgba(0, 0, 0, .87); border-top-color: transparent } .p-text:hover > input + span::after, .p-text:hover > input + span::before, .p-text:hover > textarea + span::after, .p-text:hover > textarea + span::before { border-top-color: rgba(0, 0, 0, .87) } .p-text:hover > input:not(:focus):placeholder-shown, .p-text:hover > textarea:not(:focus):placeholder-shown { border-color: rgba(0, 0, 0, .87) } .p-text > input:not(:focus):placeholder-shown, .p-text > textarea:not(:focus):placeholder-shown { border-top-color: rgba(0, 0, 0, .6) } .p-text > input:not(:focus):placeholder-shown + span, .p-text > textarea:not(:focus):placeholder-shown + span { font-size: inherit; line-height: 68px } .p-text > input:not(:focus):placeholder-shown + span::after, .p-text > input:not(:focus):placeholder-shown + span::before, .p-text > textarea:not(:focus):placeholder-shown + span::after, .p-text > textarea:not(:focus):placeholder-shown + span::before { border-top-color: transparent } .p-text > input:focus, .p-text > textarea:focus { border-color: #2196f3; border-top-color: transparent; box-shadow: inset 1px 0 var(--p-safari-helper1), inset 1px 0 var(--p-safari-helper1), inset 0 -1px var(--p-safari-helper1); outline: 0 } .p-text > input:focus + span, .p-text > textarea:focus + span { color: #2196f3 } .p-text > input:focus + span::after, .p-text > input:focus + span::before, .p-text > textarea:focus + span::after, .p-text > textarea:focus + span::before { border-top-color: var(--p-safari-helper1) !important; box-shadow: inset 0 1px var(--p-safari-helper1) } .p-text > input:disabled, .p-text > input:disabled + span, .p-text > textarea:disabled, .p-text > textarea:disabled + span { border-color: rgba(0, 0, 0, .38) !important; border-top-color: transparent !important; color: rgba(0, 0, 0, .38); pointer-events: none } .p-text > input:disabled + span::after, .p-text > input:disabled + span::before, .p-text > textarea:disabled + span::after, .p-text > textarea:disabled + span::before { border-top-color: rgba(0, 0, 0, .38) !important } .p-text > input:disabled:placeholder-shown, .p-text > input:disabled:placeholder-shown + span, .p-text > textarea:disabled:placeholder-shown, .p-text > textarea:disabled:placeholder-shown + span { border-top-color: rgba(0, 0, 0, .38) !important } .p-text > input:disabled:placeholder-shown + span::after, .p-text > input:disabled:placeholder-shown + span::before, .p-text > textarea:disabled:placeholder-shown + span::after, .p-text > textarea:disabled:placeholder-shown + span::before { border-top-color: transparent !important } @media not all and (min-resolution: .001dpcm) { @supports (-webkit-appearance:none) { .p-text > input, .p-text > input + span, .p-text > input + span::after, .p-text > input + span::before, .p-text > textarea, .p-text > textarea + span, .p-text > textarea + span::after, .p-text > textarea + span::before { transition-duration: .1s } } } Bitrate RTT (Round Trip Time) Latency 1 try loss % Final loss % MSS (Max Segment Size) Payload Size Flow Control window size Receive Buffer Size Source IP / Domain & Port IP / Domain Port Mode Listener Caller Result Copy How it was calculated const tooltipTriggerList = [].slice.call(document.querySelectorAll('[data-bs-toggle=\"tooltip\"]')); tooltipTriggerList.map(tooltipTriggerEl => new bootstrap.Tooltip(tooltipTriggerEl)); const btn = document.getElementsByClassName('clipboardBtn'); new ClipboardJS(btn); $('.icheck').iCheck({ checkboxClass: 'icheckbox_square-blue', radioClass: 'iradio_square-blue', }); let currentTimestamp = () => Math.floor(Date.now() / 1000); var lastChange = currentTimestamp(), lastChangeBy = 'undefined'; const ACK_BYTES = 44; const LISTENER = 'listener', CALLER = 'caller'; const rttInput = $('#msRTT-slider'), bitrateInput = $('#kbpsBitrate-slider'), mssInput = $('#byteMSS-slider'), payloadSizeInput = $('#bytesPayloadSize-slider'), lossPossibleInput = $('#lossPossible-slider'), lossAfterRetriesInput = $('#lossAfterRetries-slider'), latencyInput = $('#msLatency-slider'), fcOutput = $('#fc-slider'), rcvbufOutput = $('#rcvbuf-slider'), configCode = document.getElementById('configCode'), howCode = document.getElementById('howCode'), srcInput = document.getElementById('srcInput'), portInput = document.getElementById('portInput'); let calcParams = () => { const rtt = parseFloat(rttInput.val()), kbps = parseFloat(bitrateInput.val()), mss = parseFloat(mssInput.val()), payloadSize = parseFloat(payloadSizeInput.val()), latency = parseFloat(latencyInput.val()); const fullLatencySec = (latency + rtt / 2) / 1000; const targetPayloadBytes = Math.floor(fullLatencySec * kbps * 1000 / 8); let targetNumPackets = Math.floor(targetPayloadBytes / payloadSize); if (targetNumPackets < 32) targetNumPackets = 32; const udphdrSize = 28; const targetSizeValue = targetNumPackets * (mss - udphdrSize); fcOutput.data('ionRangeSlider').update({from: targetNumPackets}); rcvbufOutput.data('ionRangeSlider').update({from: targetSizeValue}); howCode.innerHTML = `<p>According to <a target=\"_blank\" href=\"https://github.com/Haivision/srt/blob/master/docs/API/configuration-guidelines.md\">Configuration Guidelines</a>:</p> <code class=\"text-break text-body\"> udphdrSize = 28 <br> fullLatencySec = (latency + rtt / 2) / 1000 = (${latency} + ${rtt} / 2) / 1000 = ${fullLatencySec} <br> targetPayloadBytes = fullLatencySec * kbps * 1000 / 8 = ${fullLatencySec} * ${kbps} * 1000 / 8 = ${targetPayloadBytes} <br> flowControlWindowSize = targetNumPackets = targetPayloadBytes / payloadSize = ${targetPayloadBytes} / ${payloadSize} = ${targetNumPackets} <br> receiveBufferSize = targetSizeValue = targetNumPackets * (mss - udphdrSize) = ${targetNumPackets} * (${mss} - ${udphdrSize}) = ${targetSizeValue} </code>`; calcConfig(mss, payloadSize, latency, targetNumPackets, targetSizeValue); }; let calcConfig = (mss = mssInput.val(), payloadSize = payloadSizeInput.val(), latency = latencyInput.val(), fc = fcOutput.val(), rcvbuf = rcvbufOutput.val()) => { const mode = $('input[name=mode]:checked').val(); if (!mode) return; const src = srcInput.value, port = portInput.value; let srcValue = mode === CALLER ? src : ''; let srtString = (`\\ srt://${srcValue}:${port}\\ ?mode=${mode}\\ &transtype=live\\ &rcvlatency=${latency}\\ &peerlatency=${latency}\\ &mss=${mss}\\ &payloadsize=${payloadSize}\\ &fc=${fc}\\ &rcvbuf=${rcvbuf}\\ `); configCode.innerText = srtString; }; function callerName() { return callerName.caller?.name; } function onRTTChanged(value) { $('#lossPossible-slider').change() console.log(callerName()); calcParams(); } function onBitrateChanged(value) { console.log(callerName()); calcParams(); } function onMSSChanged(value) { if (payloadSizeInput.val() > Number(value) - ACK_BYTES) { payloadSizeInput.data('ionRangeSlider').update({from: Number(value) - ACK_BYTES}); } console.log(callerName()); calcParams(); } function onPayloadSizeChanged(value) { if (mssInput.val() < Number(value) + ACK_BYTES) { mssInput.data('ionRangeSlider').update({from: Number(value) + ACK_BYTES}); } console.log(callerName()); calcParams(); } function calcLatencyLosses(rtt, lossPossiblePercent, lossAfterRetriesPercent) { if (lossPossiblePercent !== 0) { let ResendFailProb = lossAfterRetriesPercent / 100 let FailProb = lossPossiblePercent / 100 let tries = Math.log(ResendFailProb) / Math.log(FailProb) tries = Math.ceil(tries) let latency = rtt * tries // if (Number(latencyInput.val()) < minLatency) latencyInput.data('ionRangeSlider').update({from: latency}) } } function onlossPossibleChanged(value) { console.log(callerName()); if (lastChange !== currentTimestamp() || lastChangeBy === callerName()) { let rtt = Number(rttInput.val()), lossPossiblePercent = Number(value), lossAfterRetriesPercent = Number(lossAfterRetriesInput.val()) calcLatencyLosses(rtt, lossPossiblePercent, lossAfterRetriesPercent) } lastChange = currentTimestamp() lastChangeBy = callerName() } function onLossAfterRetriesChanged(value) { console.log(callerName()); if (lastChange !== currentTimestamp() || lastChangeBy === callerName()) { let rtt = Number(rttInput.val()), lossPossiblePercent = Number(lossPossibleInput.val()), lossAfterRetriesPercent = Number(value) calcLatencyLosses(rtt, lossPossiblePercent, lossAfterRetriesPercent) } lastChange = currentTimestamp() lastChangeBy = callerName() } function onLatencyChanged(value) { console.log(callerName()); if (lastChange !== currentTimestamp() || lastChangeBy === callerName()) { let rtt = Number(rttInput.val()), lossPossiblePercent = Number(lossPossibleInput.val()), latency = Number(value) let retries = Math.floor(latency / rtt) // 2 let ResendFailProb = retries === 0 ? lossPossiblePercent / 100 : Math.pow(lossPossiblePercent / 100, retries + 1) let lossAfterRetriesPercent = Math.max(ResendFailProb * 100, 0.01) console.log({value, retries, ResendFailProb, lossAfterRetriesPercent}) lastChange = currentTimestamp() lastChangeBy = callerName() if (lossAfterRetriesInput.val() != lossAfterRetriesPercent) lossAfterRetriesInput.data('ionRangeSlider').update({from: lossAfterRetriesPercent}) } calcParams(); } function onFCChanged(value) { calcConfig(); } function onRCVBUFChanged(value) { calcConfig(); } function onListenerClick(value) { calcConfig(); } function onCallerClick(value) { calcConfig(); } function onSrcChanged(value) { calcConfig(); } function onPortChanged(value) { calcConfig(); } rttInput.ionRangeSlider({ skin: 'round', grid: true, min: 0, max: 500, step: 5, from: 100, postfix: ' ms' }); bitrateInput.ionRangeSlider({ skin: 'round', grid: true, min: 100, max: 20000, step: 100, from: 8000, postfix: ' kbps' }); mssInput.ionRangeSlider({ skin: 'round', grid: true, min: 244, max: 1500, step: 1, from: 1360, postfix: ' bytes' }); payloadSizeInput.ionRangeSlider({ skin: 'round', grid: true, min: 200, max: 1456, step: 1, from: 1316, postfix: ' bytes' }); lossPossibleInput.ionRangeSlider({ skin: 'round', grid: true, min: 0, max: 100, step: 0.1, from: 1, postfix: ' %' }); lossAfterRetriesInput.ionRangeSlider({ skin: 'round', grid: true, min: 0.01, max: 100, step: 0.01, from: 0.01, postfix: ' %' }); latencyInput.ionRangeSlider({ skin: 'round', grid: true, min: 0, max: 5000, step: 10, from: 300, postfix: ' ms' }); fcOutput.ionRangeSlider({ skin: 'round', grid: true, min: 0, max: 10000, step: 1, postfix: ' packets', block: false }); rcvbufOutput.ionRangeSlider({ skin: 'round', grid: true, min: 0, max: 20000000, step: 100, postfix: ' bytes', block: false }); console.log(callerName()); calcParams();","title":"SRT Configuration Calculator"},{"location":"protocol/configuration/#srt-configuration-calculator","text":".p-text { --p-safari-helper1: rgb(33, 150, 243); position: relative; display: inline-block; padding-top: 6px; font-family: var(--p-font, \"Roboto\", \"Segoe UI\", BlinkMacSystemFont, system-ui, -apple-system); font-size: 16px; line-height: 1.5; overflow: hidden } .p-text > input, .p-text > textarea { box-sizing: border-box; margin: 0; border: 1px solid rgba(0, 0, 0, .6); border-top-color: transparent; border-radius: 4px; padding: 15px 13px 15px; width: 100%; height: inherit; color: rgba(0, 0, 0, .87); background-color: transparent; box-shadow: none; font-family: inherit; font-size: inherit; line-height: inherit; caret-color: #2196f3; transition: border .2s, box-shadow .2s } .p-text > input + span, .p-text > textarea + span { position: absolute; top: 0; left: 0; display: flex; border-color: rgba(0, 0, 0, .6); width: 100%; max-height: 100%; color: rgba(0, 0, 0, .6); font-size: 75%; line-height: 15px; cursor: text; transition: color .2s, font-size .2s, line-height .2s } .p-text > input + span::after, .p-text > input + span::before, .p-text > textarea + span::after, .p-text > textarea + span::before { content: \"\"; display: block; box-sizing: border-box; margin-top: 6px; border-top: solid 1px; border-top-color: rgba(0, 0, 0, .6); min-width: 10px; height: 8px; pointer-events: none; box-shadow: inset 0 1px transparent; transition: border-color .2s, box-shadow .2s } .p-text > input + span::before, .p-text > textarea + span::before { margin-right: 4px; border-left: solid 1px transparent; border-radius: 4px 0 } .p-text > input + span::after, .p-text > textarea + span::after { flex-grow: 1; margin-left: 4px; border-right: solid 1px transparent; border-radius: 0 4px } .p-text:hover > input, .p-text:hover > textarea { border-color: rgba(0, 0, 0, .87); border-top-color: transparent } .p-text:hover > input + span::after, .p-text:hover > input + span::before, .p-text:hover > textarea + span::after, .p-text:hover > textarea + span::before { border-top-color: rgba(0, 0, 0, .87) } .p-text:hover > input:not(:focus):placeholder-shown, .p-text:hover > textarea:not(:focus):placeholder-shown { border-color: rgba(0, 0, 0, .87) } .p-text > input:not(:focus):placeholder-shown, .p-text > textarea:not(:focus):placeholder-shown { border-top-color: rgba(0, 0, 0, .6) } .p-text > input:not(:focus):placeholder-shown + span, .p-text > textarea:not(:focus):placeholder-shown + span { font-size: inherit; line-height: 68px } .p-text > input:not(:focus):placeholder-shown + span::after, .p-text > input:not(:focus):placeholder-shown + span::before, .p-text > textarea:not(:focus):placeholder-shown + span::after, .p-text > textarea:not(:focus):placeholder-shown + span::before { border-top-color: transparent } .p-text > input:focus, .p-text > textarea:focus { border-color: #2196f3; border-top-color: transparent; box-shadow: inset 1px 0 var(--p-safari-helper1), inset 1px 0 var(--p-safari-helper1), inset 0 -1px var(--p-safari-helper1); outline: 0 } .p-text > input:focus + span, .p-text > textarea:focus + span { color: #2196f3 } .p-text > input:focus + span::after, .p-text > input:focus + span::before, .p-text > textarea:focus + span::after, .p-text > textarea:focus + span::before { border-top-color: var(--p-safari-helper1) !important; box-shadow: inset 0 1px var(--p-safari-helper1) } .p-text > input:disabled, .p-text > input:disabled + span, .p-text > textarea:disabled, .p-text > textarea:disabled + span { border-color: rgba(0, 0, 0, .38) !important; border-top-color: transparent !important; color: rgba(0, 0, 0, .38); pointer-events: none } .p-text > input:disabled + span::after, .p-text > input:disabled + span::before, .p-text > textarea:disabled + span::after, .p-text > textarea:disabled + span::before { border-top-color: rgba(0, 0, 0, .38) !important } .p-text > input:disabled:placeholder-shown, .p-text > input:disabled:placeholder-shown + span, .p-text > textarea:disabled:placeholder-shown, .p-text > textarea:disabled:placeholder-shown + span { border-top-color: rgba(0, 0, 0, .38) !important } .p-text > input:disabled:placeholder-shown + span::after, .p-text > input:disabled:placeholder-shown + span::before, .p-text > textarea:disabled:placeholder-shown + span::after, .p-text > textarea:disabled:placeholder-shown + span::before { border-top-color: transparent !important } @media not all and (min-resolution: .001dpcm) { @supports (-webkit-appearance:none) { .p-text > input, .p-text > input + span, .p-text > input + span::after, .p-text > input + span::before, .p-text > textarea, .p-text > textarea + span, .p-text > textarea + span::after, .p-text > textarea + span::before { transition-duration: .1s } } } Bitrate RTT (Round Trip Time) Latency 1 try loss % Final loss % MSS (Max Segment Size) Payload Size Flow Control window size Receive Buffer Size","title":"SRT Configuration Calculator"},{"location":"protocol/events-and-timers/","text":"Control Events and Timers Timers LastRSP time is updated when SRT socket is created, when a connection is established (since SRT v1.3.3, PR #745 ), upon receiving a control or data packet. LastRspAck time is updated when SRT socket is created, when a connection is established (since SRT v1.3.3, PR #745 ), an ACK packet for yet unacknowledged packet is received, and also if the sender's buffer has no unacknowledged packets on the new data submitted by srt_sendmsg() . LastSND timer is updated when SRT socket is created, when a connection is established (since SRT v1.3.3, PR #745 ), when a control or data packet is sent. A special update happens when a handshake message is sent in response to incomming handshare packet (this does not happen via sendCtrl()). The value is used to trigger sending a KEEPALIVE message. See Sec. Keepalive Messages. NextACK time. NextNAK time. TargetSND time (TargetTime - rename in source code?) is used in the sender only for rate-based packet sending. In UDT draft referred to as SND timer. Events SRT has different events: ACK, NAK, EXP, SND and RSP. Each event has its own period and they are all independent. They use the system time as origins and should process wrapping if the system time wraps. For a certain periodical event E in SRT, suppose the time variable is ET and its period is p. If E is set or reset at system time t0 (ET = t0), then at any time t1, (t1 - ET >= p) is the condition to check if E should be triggered. ACK is used to trigger an acknowledgment (ACK). Its period is set by the congestion control module, otherwise the default value of 10 ms is used (COMM_SYN_INTERVAL or SYN time). However, SRT will send an ACK no longer than every 0.01 second, even though the congestion control does not need timer-based ACK. Here, 0.01 second is defined as the SYN time, or synchronization time, and it affects many of the other timers used in SRT. NAK is used to trigger a negative acknowledgment (NAK). Its period is dynamically updated to RTT + 4 \u00d7 RTTVar + SYN, where RTTVar is the variance of RTT samples. EXP is used to trigger data packets retransmission and maintain connection status. Its period is dynamically updated to N \u00d7 (RTT + 4 \u00d7 RTTVar + SYN), where N is the number of continuous timeouts. To avoid unnecessary timeout, a minimum threshold (e.g., 0.5 second) should be used in the implementation. UDT: 4 \u00d7 RTT + RTTVar Note that 4 \u00d7 RTT + RTTVar + SYN is described in the UDT draft (Timers section). However, the formula actually used in the UDT v4 source code is RTT + 4 \u00d7 RTTVar + SYN, which is also used in the SRT (as of v1.3.2). UDT v3 just uses 1 sec timeout. In the rest of this document, a name of a time variable will be used to represent the associated event, the variable itself, or the value of its period, depending on the context. For example, ACK can mean either the ACK event or the value of ACK period. Connection Expiration Default 5 seconds. Can be configured by SRTO_PEERIDLETIMEO. TODO: Add details Describe in more details, as it relies on several timers. EXP Event Processing (Currently just copied from UDT draft). Put all the unacknowledged packets into the sender's loss list. If (ExpCount > 16) and at least 3 seconds has elapsed since that last time when ExpCount is reset to 1, or, 3 minutes has elapsed, close the UDT connection and exit. If the sender's loss list is empty, send a keep-alive packet to the peer side. Increase ExpCount by 1. Acknowledgement Messages There are several types of ACK packets: lite ACK, small ACK and full ACK. The default ACK interval ACKInt is 10 ms ( CUDT::m_ullACKInt_tk ). The Congestion Control module can specify a custom ACK interval by overriding the SrtCongestionControlBase::ACKIntervalMicrosec() . Neither LiveCC, nor FileCC specify this value. NextACK time is set to tcur + ACKInt at the start when SRT socket is created and updated when a connection is established (since SRT v1.3.3, PR #745 ). The value is updated on every ACK packet sent as NextACK = tcur + ACKInt, where ACKInt = CC::ACKInt\u00b5s ? CC::ACKInt\u00b5s : CUDT::ACKInt. ACK packet is sent if tcur > NextACK or if Pktsrcvd >= CC::ACKIntpkts, where CC::ACKIntpkts is specified by the Congestion Control. Neither LiveCC, nor FileCC specify this value. Congestion control can also schedule sending the ACK by setting NextACK = tcur if CC::needsQuickACK() returns true. By default LiveCC returns false, and FileCC returns true if the payload size is less than the maximum size (end of file detection). A lite ACK is sent if Pktsrcvd >= 64 (CC:: SELF_CLOCK_INTERVAL). A full ACK is sent if tcur ACKLast > ACKInt. Otherwise a small ACK is sent. ACK for the same sequence may be sent again if tcur - ACKLast >= RTT + 4 \u00d7 RTTVar (see CUDT::sendCtrl()). Keepalive Messages Keepalive messages in SRT are sent based on the LAST_SND timer. LAST_SND timer is updated by the latest control or data packet sent. A KEEPALIVE message is sent if t >= LAST_SND + KEEPALIVE_PERIOD, where KEEPALIVE_PERIOD = 1 sec. Keepalive messages in UDT are sent based on the EXP timer. EXP event is triggered at t >= N \u00d7 (RTT + 4 \u00d7 RTTVar + SYN), where N is the number of continuous timeouts. If N >= 16, the connection is closed. Otherwise if the senders buffer has unacknowledged packets, they are considered lost, added to the lost list, thus scheduled for retransmission. If the sender's buffer has no unacknowledged packets, a KEEPALIVE control packet is sent.It can be calculated, that for an idle connection a KEEPALIVE is sent every RTT + 4 \u00d7 RTTVar + SYN. NAK Reports Sent by Receiver A negative acknowledgment (NAK) report is special SRT control packet, sent by the receiver back to the sender. The packet holds compressed sequence numbers of packets considered lost by the receiver. There are two possibilities for the receiver to report a loss back to the sender. Triggered by Loss Detection Loss detection is based on Gaps in Sequence Numbers. Detection of a packet loss is triggered with the newly received packet. An offset between the newly arrived packet and the last acknowledged position is calculated. In case the offset is negative, the packet is considered belated, meaning that it was either already acknowledged or dropped by TSBPD as too late to be delivered. Such belated packets are ignored. Documentation states the retransmitted packet is not considered belated Check statistics handling any packets after receiver ACK as belated, regardless of the retransmit flag. Should the re-transmitted packets be ignored? An offset between sequence numbers of the arrived packet and the previously received packet is calculated. If the packet is not the next packet in order, then a loss detection mechanism is triggered. First, a gap in sequence numbers of the consecutively received packets might be due to packet reordering. Sequence numbers that should fill the gap are added to the RcvLossList of a socket. Then there is a decision whether a loss report should be sent. A non-zero reorder tolerance (ReorderTolerance <= MaxReorderTolerance) determines if a gap in sequence numbers is allowed. The default value of MaxReorderTolerance is zero, and it can be set with SRTO_LOSSMAXTTL socket option. If ReorderTolerance==0, a loss report is sent immediately for the detected gap. Otherwise, if ReorderTolerance>0, then the detected gap is added to a temporal loss list, with a TTL value equal to current ReorderTolerance value. Each time a DATA packet is received, TTTL of every lost packet in this temporal loss list is decremented by 1. Those packets TODO: Describe ReorderTolerance update logic Example from SRT Periodic NAK Reports showing how a serial loss will be treated. Packets in Transit | Receive Buffer | | Largest sequence number received (4) | New / +---+ +---+ | +---+ +---+---+---+---+---+---+ --- | 9 | --- | 8 | ---> | --->| 7 | + | _ | _ | 4 | 3 | _ | 1 | ---> +---+ +---+ | +---+ | +---+---+---+---+---+---+ | | \\_____/ \\_/ +---+ | +---+ | \\____________/ <--- |NAK| <--- | <---|NAK|-+ Missing packets | 2 | | |5,6| +---+ | +---+ Triggered by Periodic NAK Reports See also SRT Periodic NAK Reports . By default periodic NAK reports are enabled in live mode (SRTO_TRANSTYPE = SRTT_LIVE), and disabled in file mode (SRTO_TRANSTYPE = SRTT_FILE). The functionality is controlled by SRTO_NAKREPORT socket option. NAKtime is the time to send the next periodic NAK report. When t >= NAKtime and the RcvLossList is not empty, a periodic NAK report is sent. This report includes all the packets in the receiver's loss list ( RcvLossList ). | Receive Buffer | | Largest sequence number received (7) | / | +---+---+---+---+---+---+---+ | --->| 7 | _ | _ | 4 | 3 | _ | 1 | ---> | +---+---+---+---+---+---+---+ | | \\_____/ \\_/ | +-----+ | \\____________/ | <-| NAK |-+ Missing packets | |2,5,6| | +-----+ NAKtime is first initialized when a socket is created, and updated after a connection is established (since SRT v1.3.3, PR #745 ). Regularly NAKtime is updated with the last time a periodic* NAK report was sent: NAKtime = t + NAKInt***. ISSUE* #701 . NAK time is updated after sending the periodic NAK report. Should be also updated after sending a regular LOSS report? Or at least update the time if there are no losses in the RcvLossList***. where NAKInt is an interval between periodic NAK reports. Minimum NAK interval is NAKIntmin=300 ms, and it is set at the very beginning of the streaming. NAK interval NAKInt is updated after sending a loss report. The new value is NAKInt = RTT + 4 \u00d7 RTTVar . This value is passed to the CC module. FileCC can update NAKInt based on the reported receiving speed Rrcv (packets per second) and the length of the loss list LOSSlen: NAKInt = RTT + 4 \u00d7 RTTVar + LOSSlen \u00d7 106 / Rrcv. LiveCC will update NAKInt by dividing it by 2: LOSSlen: NAKInt = (RTT + 4 \u00d7 RTTVar) / 2. The minimum value is NAKInt = max(NAKInt, NAKIntmin). NAKtime is a time to send the next periodic NAK report. The time is initialized at CUDT::open() and after a connection is established (PR #745 ). NAKtime is updated with the last time a periodic NAK report was sent. ISSUE #701 . NAK time is updated after sending the periodic NAK report. Should be also updated after sending a regular LOSS report? When t >= NAKtime and the RcvLossList is not empty, a periodic NAK report is sent. This report includes all the packets in the receiver's loss list ( RcvLossList ). Packet Retransmission (Sender) Retransmission Triggered by NAK Report A packet is scheduled for retransmission if a sender receives a NAK report from the receiver. A loss report may be triggered either by loss detection, or by periodic NAK reports (see NAK Reports section above). Blind Retransmission A blind retransmission is an heuristic mechanism of a sender to trigger packet retransmission without receiving a NAK report from the receiver. Fast Retransmission (FASTREXMIT) FASTREXMIT mode is enabled by LiveCC when the receiver is not expected to send periodic NAK reports. A condition is triggered based on the LastRspAck time. Timer-triggered condition: t > N \u00d7 (RTT + 4 \u00d7 RTTVar + 2 \u00d7 SYN) + SYN, where SYN=10 ms, and N is a number of such retransmissions since last ACK (also reset if the sender's buffer has no unacknowledged packets on the new data submitted by srt_sendmsg). All unacknowledged packets in the sender's buffer are added to the SndLossList and scheduled for retransmission. FASTREXMIT is not present in UDT. Late Retransmission (LATEREXMIT) TODO: User-defined RTT Describe a scenario with a user-defined RTO value. The LATEREXMIT is the default blind retransmission mode of UDT. LATEREXMIT is triggered by the EXP timer. EXP timer in UDT is used to trigger data packets retransmission and maintain connection status. Its period is dynamically updated to N \u00d7 (RTT + 4 \u00d7 RTTVar + SYN), where N is the number of continuous timeouts. To avoid unnecessary timeout, a minimum threshold (e.g., 0.5 second) is used in the implementation. Each time EXP timer is triggered, resend unacknowledged packets currently in the sender's buffer if there are some, otherwise send a KEEPALIVE message. In SRT v1.3.2 and earlier the logic is the same, except that a KEEPALIVE message has its own timer and a timeout of 1 second (see keepalive section above). TODO: Check if excessive KEEPALIVE messages are sent after a retransmission is scheduled.","title":"Control Events and Timers"},{"location":"protocol/events-and-timers/#control-events-and-timers","text":"","title":"Control Events and Timers"},{"location":"protocol/events-and-timers/#timers","text":"LastRSP time is updated when SRT socket is created, when a connection is established (since SRT v1.3.3, PR #745 ), upon receiving a control or data packet. LastRspAck time is updated when SRT socket is created, when a connection is established (since SRT v1.3.3, PR #745 ), an ACK packet for yet unacknowledged packet is received, and also if the sender's buffer has no unacknowledged packets on the new data submitted by srt_sendmsg() . LastSND timer is updated when SRT socket is created, when a connection is established (since SRT v1.3.3, PR #745 ), when a control or data packet is sent. A special update happens when a handshake message is sent in response to incomming handshare packet (this does not happen via sendCtrl()). The value is used to trigger sending a KEEPALIVE message. See Sec. Keepalive Messages. NextACK time. NextNAK time. TargetSND time (TargetTime - rename in source code?) is used in the sender only for rate-based packet sending. In UDT draft referred to as SND timer.","title":"Timers"},{"location":"protocol/events-and-timers/#events","text":"SRT has different events: ACK, NAK, EXP, SND and RSP. Each event has its own period and they are all independent. They use the system time as origins and should process wrapping if the system time wraps. For a certain periodical event E in SRT, suppose the time variable is ET and its period is p. If E is set or reset at system time t0 (ET = t0), then at any time t1, (t1 - ET >= p) is the condition to check if E should be triggered. ACK is used to trigger an acknowledgment (ACK). Its period is set by the congestion control module, otherwise the default value of 10 ms is used (COMM_SYN_INTERVAL or SYN time). However, SRT will send an ACK no longer than every 0.01 second, even though the congestion control does not need timer-based ACK. Here, 0.01 second is defined as the SYN time, or synchronization time, and it affects many of the other timers used in SRT. NAK is used to trigger a negative acknowledgment (NAK). Its period is dynamically updated to RTT + 4 \u00d7 RTTVar + SYN, where RTTVar is the variance of RTT samples. EXP is used to trigger data packets retransmission and maintain connection status. Its period is dynamically updated to N \u00d7 (RTT + 4 \u00d7 RTTVar + SYN), where N is the number of continuous timeouts. To avoid unnecessary timeout, a minimum threshold (e.g., 0.5 second) should be used in the implementation. UDT: 4 \u00d7 RTT + RTTVar Note that 4 \u00d7 RTT + RTTVar + SYN is described in the UDT draft (Timers section). However, the formula actually used in the UDT v4 source code is RTT + 4 \u00d7 RTTVar + SYN, which is also used in the SRT (as of v1.3.2). UDT v3 just uses 1 sec timeout. In the rest of this document, a name of a time variable will be used to represent the associated event, the variable itself, or the value of its period, depending on the context. For example, ACK can mean either the ACK event or the value of ACK period.","title":"Events"},{"location":"protocol/events-and-timers/#connection-expiration","text":"Default 5 seconds. Can be configured by SRTO_PEERIDLETIMEO. TODO: Add details Describe in more details, as it relies on several timers. EXP Event Processing (Currently just copied from UDT draft). Put all the unacknowledged packets into the sender's loss list. If (ExpCount > 16) and at least 3 seconds has elapsed since that last time when ExpCount is reset to 1, or, 3 minutes has elapsed, close the UDT connection and exit. If the sender's loss list is empty, send a keep-alive packet to the peer side. Increase ExpCount by 1.","title":"Connection Expiration"},{"location":"protocol/events-and-timers/#acknowledgement-messages","text":"There are several types of ACK packets: lite ACK, small ACK and full ACK. The default ACK interval ACKInt is 10 ms ( CUDT::m_ullACKInt_tk ). The Congestion Control module can specify a custom ACK interval by overriding the SrtCongestionControlBase::ACKIntervalMicrosec() . Neither LiveCC, nor FileCC specify this value. NextACK time is set to tcur + ACKInt at the start when SRT socket is created and updated when a connection is established (since SRT v1.3.3, PR #745 ). The value is updated on every ACK packet sent as NextACK = tcur + ACKInt, where ACKInt = CC::ACKInt\u00b5s ? CC::ACKInt\u00b5s : CUDT::ACKInt. ACK packet is sent if tcur > NextACK or if Pktsrcvd >= CC::ACKIntpkts, where CC::ACKIntpkts is specified by the Congestion Control. Neither LiveCC, nor FileCC specify this value. Congestion control can also schedule sending the ACK by setting NextACK = tcur if CC::needsQuickACK() returns true. By default LiveCC returns false, and FileCC returns true if the payload size is less than the maximum size (end of file detection). A lite ACK is sent if Pktsrcvd >= 64 (CC:: SELF_CLOCK_INTERVAL). A full ACK is sent if tcur ACKLast > ACKInt. Otherwise a small ACK is sent. ACK for the same sequence may be sent again if tcur - ACKLast >= RTT + 4 \u00d7 RTTVar (see CUDT::sendCtrl()).","title":"Acknowledgement Messages"},{"location":"protocol/events-and-timers/#keepalive-messages","text":"Keepalive messages in SRT are sent based on the LAST_SND timer. LAST_SND timer is updated by the latest control or data packet sent. A KEEPALIVE message is sent if t >= LAST_SND + KEEPALIVE_PERIOD, where KEEPALIVE_PERIOD = 1 sec. Keepalive messages in UDT are sent based on the EXP timer. EXP event is triggered at t >= N \u00d7 (RTT + 4 \u00d7 RTTVar + SYN), where N is the number of continuous timeouts. If N >= 16, the connection is closed. Otherwise if the senders buffer has unacknowledged packets, they are considered lost, added to the lost list, thus scheduled for retransmission. If the sender's buffer has no unacknowledged packets, a KEEPALIVE control packet is sent.It can be calculated, that for an idle connection a KEEPALIVE is sent every RTT + 4 \u00d7 RTTVar + SYN.","title":"Keepalive Messages"},{"location":"protocol/events-and-timers/#nak-reports-sent-by-receiver","text":"A negative acknowledgment (NAK) report is special SRT control packet, sent by the receiver back to the sender. The packet holds compressed sequence numbers of packets considered lost by the receiver. There are two possibilities for the receiver to report a loss back to the sender.","title":"NAK Reports Sent by Receiver"},{"location":"protocol/events-and-timers/#triggered-by-loss-detection","text":"Loss detection is based on Gaps in Sequence Numbers. Detection of a packet loss is triggered with the newly received packet. An offset between the newly arrived packet and the last acknowledged position is calculated. In case the offset is negative, the packet is considered belated, meaning that it was either already acknowledged or dropped by TSBPD as too late to be delivered. Such belated packets are ignored. Documentation states the retransmitted packet is not considered belated Check statistics handling any packets after receiver ACK as belated, regardless of the retransmit flag. Should the re-transmitted packets be ignored? An offset between sequence numbers of the arrived packet and the previously received packet is calculated. If the packet is not the next packet in order, then a loss detection mechanism is triggered. First, a gap in sequence numbers of the consecutively received packets might be due to packet reordering. Sequence numbers that should fill the gap are added to the RcvLossList of a socket. Then there is a decision whether a loss report should be sent. A non-zero reorder tolerance (ReorderTolerance <= MaxReorderTolerance) determines if a gap in sequence numbers is allowed. The default value of MaxReorderTolerance is zero, and it can be set with SRTO_LOSSMAXTTL socket option. If ReorderTolerance==0, a loss report is sent immediately for the detected gap. Otherwise, if ReorderTolerance>0, then the detected gap is added to a temporal loss list, with a TTL value equal to current ReorderTolerance value. Each time a DATA packet is received, TTTL of every lost packet in this temporal loss list is decremented by 1. Those packets TODO: Describe ReorderTolerance update logic Example from SRT Periodic NAK Reports showing how a serial loss will be treated. Packets in Transit | Receive Buffer | | Largest sequence number received (4) | New / +---+ +---+ | +---+ +---+---+---+---+---+---+ --- | 9 | --- | 8 | ---> | --->| 7 | + | _ | _ | 4 | 3 | _ | 1 | ---> +---+ +---+ | +---+ | +---+---+---+---+---+---+ | | \\_____/ \\_/ +---+ | +---+ | \\____________/ <--- |NAK| <--- | <---|NAK|-+ Missing packets | 2 | | |5,6| +---+ | +---+","title":"Triggered by Loss Detection"},{"location":"protocol/events-and-timers/#triggered-by-periodic-nak-reports","text":"See also SRT Periodic NAK Reports . By default periodic NAK reports are enabled in live mode (SRTO_TRANSTYPE = SRTT_LIVE), and disabled in file mode (SRTO_TRANSTYPE = SRTT_FILE). The functionality is controlled by SRTO_NAKREPORT socket option. NAKtime is the time to send the next periodic NAK report. When t >= NAKtime and the RcvLossList is not empty, a periodic NAK report is sent. This report includes all the packets in the receiver's loss list ( RcvLossList ). | Receive Buffer | | Largest sequence number received (7) | / | +---+---+---+---+---+---+---+ | --->| 7 | _ | _ | 4 | 3 | _ | 1 | ---> | +---+---+---+---+---+---+---+ | | \\_____/ \\_/ | +-----+ | \\____________/ | <-| NAK |-+ Missing packets | |2,5,6| | +-----+ NAKtime is first initialized when a socket is created, and updated after a connection is established (since SRT v1.3.3, PR #745 ). Regularly NAKtime is updated with the last time a periodic* NAK report was sent: NAKtime = t + NAKInt***. ISSUE* #701 . NAK time is updated after sending the periodic NAK report. Should be also updated after sending a regular LOSS report? Or at least update the time if there are no losses in the RcvLossList***. where NAKInt is an interval between periodic NAK reports. Minimum NAK interval is NAKIntmin=300 ms, and it is set at the very beginning of the streaming. NAK interval NAKInt is updated after sending a loss report. The new value is NAKInt = RTT + 4 \u00d7 RTTVar . This value is passed to the CC module. FileCC can update NAKInt based on the reported receiving speed Rrcv (packets per second) and the length of the loss list LOSSlen: NAKInt = RTT + 4 \u00d7 RTTVar + LOSSlen \u00d7 106 / Rrcv. LiveCC will update NAKInt by dividing it by 2: LOSSlen: NAKInt = (RTT + 4 \u00d7 RTTVar) / 2. The minimum value is NAKInt = max(NAKInt, NAKIntmin). NAKtime is a time to send the next periodic NAK report. The time is initialized at CUDT::open() and after a connection is established (PR #745 ). NAKtime is updated with the last time a periodic NAK report was sent. ISSUE #701 . NAK time is updated after sending the periodic NAK report. Should be also updated after sending a regular LOSS report? When t >= NAKtime and the RcvLossList is not empty, a periodic NAK report is sent. This report includes all the packets in the receiver's loss list ( RcvLossList ).","title":"Triggered by Periodic NAK Reports"},{"location":"protocol/events-and-timers/#packet-retransmission-sender","text":"","title":"Packet Retransmission (Sender)"},{"location":"protocol/events-and-timers/#retransmission-triggered-by-nak-report","text":"A packet is scheduled for retransmission if a sender receives a NAK report from the receiver. A loss report may be triggered either by loss detection, or by periodic NAK reports (see NAK Reports section above).","title":"Retransmission Triggered by NAK Report"},{"location":"protocol/events-and-timers/#blind-retransmission","text":"A blind retransmission is an heuristic mechanism of a sender to trigger packet retransmission without receiving a NAK report from the receiver.","title":"Blind Retransmission"},{"location":"protocol/events-and-timers/#fast-retransmission-fastrexmit","text":"FASTREXMIT mode is enabled by LiveCC when the receiver is not expected to send periodic NAK reports. A condition is triggered based on the LastRspAck time. Timer-triggered condition: t > N \u00d7 (RTT + 4 \u00d7 RTTVar + 2 \u00d7 SYN) + SYN, where SYN=10 ms, and N is a number of such retransmissions since last ACK (also reset if the sender's buffer has no unacknowledged packets on the new data submitted by srt_sendmsg). All unacknowledged packets in the sender's buffer are added to the SndLossList and scheduled for retransmission. FASTREXMIT is not present in UDT.","title":"Fast Retransmission (FASTREXMIT)"},{"location":"protocol/events-and-timers/#late-retransmission-laterexmit","text":"TODO: User-defined RTT Describe a scenario with a user-defined RTO value. The LATEREXMIT is the default blind retransmission mode of UDT. LATEREXMIT is triggered by the EXP timer. EXP timer in UDT is used to trigger data packets retransmission and maintain connection status. Its period is dynamically updated to N \u00d7 (RTT + 4 \u00d7 RTTVar + SYN), where N is the number of continuous timeouts. To avoid unnecessary timeout, a minimum threshold (e.g., 0.5 second) is used in the implementation. Each time EXP timer is triggered, resend unacknowledged packets currently in the sender's buffer if there are some, otherwise send a KEEPALIVE message. In SRT v1.3.2 and earlier the logic is the same, except that a KEEPALIVE message has its own timer and a timeout of 1 second (see keepalive section above). TODO: Check if excessive KEEPALIVE messages are sent after a retransmission is scheduled.","title":"Late Retransmission (LATEREXMIT)"},{"location":"protocol/overhead/","text":"SRT Protocol Overhead :root { --ion-safe-area-top: 20px; --ion-safe-area-bottom: 22px; } function calcOverhead(Mbps, loss_ratio, latency_xrtt) { const bps = Mbps * 1000000; const MAX_PLD = 1316; const DATA_HDR_BYTES = 24; const ACK_BYTES = 44; const ACKACK_BYTES = 16; const NAK_BYTES = 16 + 4; const data_pkts = Math.ceil(bps / (8 * MAX_PLD)); const data_hdr_bytes = data_pkts * DATA_HDR_BYTES; const ack_pkts = 1000 / 10; // Every 10 ms const ack_bytes = ack_pkts * ACK_BYTES; const ackack_bytes = ack_pkts * ACKACK_BYTES; const lost_pkts = Math.ceil(data_pkts * loss_ratio); const nak_bytes = lost_pkts * NAK_BYTES; // TODO: latency of 1RTT const resend_bytes = lost_pkts * (MAX_PLD + DATA_HDR_BYTES) //console.log(\"Bitrate \" + Mbps + \" num pkts \" + data_pkts + \" lost pkts \" + lost_pkts + \" resend \" + resend_bytes); return { dataHdrBytes: data_hdr_bytes, ackBytes: ack_bytes, ackackBytes: ackack_bytes, nakBytes: nak_bytes, resendBytes: resend_bytes }; } function createDataSet(beginMbps, endMbps, stepMbps, lossRatio = 0) { let bitrates = []; let dataHeaderBits = []; let ackBits = []; let ackackBits = []; let nakBits = []; let resendBits = []; // _.range([start], stop, [step]) // _.range(10); // => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] for (let Mbps = beginMbps; Mbps < endMbps; Mbps += stepMbps) { //console.log(Mbps); //const {dataHdrBits, ackBits, ackackBits, nakBits, resendBits} = calcOverhead(Mbps, 0, 0); const {dataHdrBytes, ackBytes, ackackBytes, nakBytes, resendBytes} = calcOverhead(Mbps, lossRatio, 0); bitrates.push(Mbps); dataHeaderBits.push(((8 * dataHdrBytes) / (Mbps * 10000)).toFixed(3)); ackBits.push(((8 * ackBytes) / (Mbps * 10000)).toFixed(3)); ackackBits.push(((8 * ackackBytes) / (Mbps * 10000)).toFixed(3)); nakBits.push(((8 * nakBytes) / (Mbps * 10000)).toFixed(3)); resendBits.push(((8 * resendBytes) / (Mbps * 10000)).toFixed(3)); } //console.log(ackackBits) return { bitratesMbps: bitrates, dataHeaderBits: dataHeaderBits, ackBits: ackBits, ackackBits: ackackBits, nakBits: nakBits, resendBits: resendBits }; } var ctx = document.getElementById(\"stacked-area-chart\").getContext(\"2d\"); const colors = { green: { fill: '#e0eadf', stroke: '#5eb84d', }, lightBlue: { stroke: '#6fccdd', }, darkBlue: { fill: '#92bed2', stroke: '#3282bf', }, purple: { fill: '#8fa8c8', stroke: '#75539e', }, }; function onLossRatioChanged(value) { //console.log(\"New value \" + value); dataSet = createDataSet(1, 30, 1, value / 100); myChart.data.datasets[0].data = dataSet.dataHeaderBits; myChart.data.datasets[1].data = dataSet.ackBits; myChart.data.datasets[2].data = dataSet.ackackBits; myChart.data.datasets[3].data = dataSet.nakBits; myChart.data.datasets[4].data = dataSet.resendBits; //console.log(myChart.data.datasets); myChart.update(); } const dataPackets = Array.from(new Array(5), (val, i)=> calcOverhead(1+ i * 5, 0, 0) ); var dataSet = createDataSet(1, 30, 1); const availableForExisting = [16, 13, 25, 33, 40, 33, 45]; const unavailable = [5, 9, 10, 9, 18, 19, 20]; var myChart = new Chart(ctx, { type: 'line', data: { labels: dataSet.bitratesMbps, datasets: [{ label: \"DATA Header Bits\", fill: true, backgroundColor: colors.purple.fill, pointBackgroundColor: colors.purple.stroke, borderColor: colors.purple.stroke, pointHighlightStroke: colors.purple.stroke, borderCapStyle: 'butt', data: dataSet.dataHeaderBits, }, { label: \"ACK Bits\", fill: true, backgroundColor: colors.darkBlue.fill, pointBackgroundColor: colors.darkBlue.stroke, borderColor: colors.darkBlue.stroke, pointHighlightStroke: colors.darkBlue.stroke, borderCapStyle: 'butt', data: dataSet.ackBits, }, { label: \"ACKACK Bits\", fill: true, backgroundColor: colors.green.fill, pointBackgroundColor: colors.lightBlue.stroke, borderColor: colors.lightBlue.stroke, pointHighlightStroke: colors.lightBlue.stroke, borderCapStyle: 'butt', data: dataSet.ackackBits, }, { label: \"NAK Bits\", fill: true, backgroundColor: colors.green.fill, pointBackgroundColor: colors.green.stroke, borderColor: colors.green.stroke, pointHighlightStroke: colors.green.stroke, data: dataSet.nakBits, }, { label: \"Resend Bits\", fill: true, backgroundColor: colors.green.fill, pointBackgroundColor: colors.green.stroke, borderColor: colors.green.stroke, pointHighlightStroke: colors.green.stroke, data: dataSet.resendBits, }] }, options: { showAllTooltips: true, responsive: false, // Can't just just `stacked: true` like the docs say scales: { yAxes: [{ stacked: true, scaleLabel: { display: true, labelString: 'Overhead, %' } }], xAxes: [{ scaleLabel: { display: true, labelString: 'Bitrate, Mbps' } }] }, animation: { duration: 750, }, } }); Loss ratio: Latency (xRTT): TODO $(\".js-range-slider\").ionRangeSlider({ skin: \"round\", grid: true, min: 0, max: 10, step: 1, from: 0, postfix: \" %\" });","title":"SRT Protocol Overhead"},{"location":"protocol/overhead/#srt-protocol-overhead","text":":root { --ion-safe-area-top: 20px; --ion-safe-area-bottom: 22px; } function calcOverhead(Mbps, loss_ratio, latency_xrtt) { const bps = Mbps * 1000000; const MAX_PLD = 1316; const DATA_HDR_BYTES = 24; const ACK_BYTES = 44; const ACKACK_BYTES = 16; const NAK_BYTES = 16 + 4; const data_pkts = Math.ceil(bps / (8 * MAX_PLD)); const data_hdr_bytes = data_pkts * DATA_HDR_BYTES; const ack_pkts = 1000 / 10; // Every 10 ms const ack_bytes = ack_pkts * ACK_BYTES; const ackack_bytes = ack_pkts * ACKACK_BYTES; const lost_pkts = Math.ceil(data_pkts * loss_ratio); const nak_bytes = lost_pkts * NAK_BYTES; // TODO: latency of 1RTT const resend_bytes = lost_pkts * (MAX_PLD + DATA_HDR_BYTES) //console.log(\"Bitrate \" + Mbps + \" num pkts \" + data_pkts + \" lost pkts \" + lost_pkts + \" resend \" + resend_bytes); return { dataHdrBytes: data_hdr_bytes, ackBytes: ack_bytes, ackackBytes: ackack_bytes, nakBytes: nak_bytes, resendBytes: resend_bytes }; } function createDataSet(beginMbps, endMbps, stepMbps, lossRatio = 0) { let bitrates = []; let dataHeaderBits = []; let ackBits = []; let ackackBits = []; let nakBits = []; let resendBits = []; // _.range([start], stop, [step]) // _.range(10); // => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] for (let Mbps = beginMbps; Mbps < endMbps; Mbps += stepMbps) { //console.log(Mbps); //const {dataHdrBits, ackBits, ackackBits, nakBits, resendBits} = calcOverhead(Mbps, 0, 0); const {dataHdrBytes, ackBytes, ackackBytes, nakBytes, resendBytes} = calcOverhead(Mbps, lossRatio, 0); bitrates.push(Mbps); dataHeaderBits.push(((8 * dataHdrBytes) / (Mbps * 10000)).toFixed(3)); ackBits.push(((8 * ackBytes) / (Mbps * 10000)).toFixed(3)); ackackBits.push(((8 * ackackBytes) / (Mbps * 10000)).toFixed(3)); nakBits.push(((8 * nakBytes) / (Mbps * 10000)).toFixed(3)); resendBits.push(((8 * resendBytes) / (Mbps * 10000)).toFixed(3)); } //console.log(ackackBits) return { bitratesMbps: bitrates, dataHeaderBits: dataHeaderBits, ackBits: ackBits, ackackBits: ackackBits, nakBits: nakBits, resendBits: resendBits }; } var ctx = document.getElementById(\"stacked-area-chart\").getContext(\"2d\"); const colors = { green: { fill: '#e0eadf', stroke: '#5eb84d', }, lightBlue: { stroke: '#6fccdd', }, darkBlue: { fill: '#92bed2', stroke: '#3282bf', }, purple: { fill: '#8fa8c8', stroke: '#75539e', }, }; function onLossRatioChanged(value) { //console.log(\"New value \" + value); dataSet = createDataSet(1, 30, 1, value / 100); myChart.data.datasets[0].data = dataSet.dataHeaderBits; myChart.data.datasets[1].data = dataSet.ackBits; myChart.data.datasets[2].data = dataSet.ackackBits; myChart.data.datasets[3].data = dataSet.nakBits; myChart.data.datasets[4].data = dataSet.resendBits; //console.log(myChart.data.datasets); myChart.update(); } const dataPackets = Array.from(new Array(5), (val, i)=> calcOverhead(1+ i * 5, 0, 0) ); var dataSet = createDataSet(1, 30, 1); const availableForExisting = [16, 13, 25, 33, 40, 33, 45]; const unavailable = [5, 9, 10, 9, 18, 19, 20]; var myChart = new Chart(ctx, { type: 'line', data: { labels: dataSet.bitratesMbps, datasets: [{ label: \"DATA Header Bits\", fill: true, backgroundColor: colors.purple.fill, pointBackgroundColor: colors.purple.stroke, borderColor: colors.purple.stroke, pointHighlightStroke: colors.purple.stroke, borderCapStyle: 'butt', data: dataSet.dataHeaderBits, }, { label: \"ACK Bits\", fill: true, backgroundColor: colors.darkBlue.fill, pointBackgroundColor: colors.darkBlue.stroke, borderColor: colors.darkBlue.stroke, pointHighlightStroke: colors.darkBlue.stroke, borderCapStyle: 'butt', data: dataSet.ackBits, }, { label: \"ACKACK Bits\", fill: true, backgroundColor: colors.green.fill, pointBackgroundColor: colors.lightBlue.stroke, borderColor: colors.lightBlue.stroke, pointHighlightStroke: colors.lightBlue.stroke, borderCapStyle: 'butt', data: dataSet.ackackBits, }, { label: \"NAK Bits\", fill: true, backgroundColor: colors.green.fill, pointBackgroundColor: colors.green.stroke, borderColor: colors.green.stroke, pointHighlightStroke: colors.green.stroke, data: dataSet.nakBits, }, { label: \"Resend Bits\", fill: true, backgroundColor: colors.green.fill, pointBackgroundColor: colors.green.stroke, borderColor: colors.green.stroke, pointHighlightStroke: colors.green.stroke, data: dataSet.resendBits, }] }, options: { showAllTooltips: true, responsive: false, // Can't just just `stacked: true` like the docs say scales: { yAxes: [{ stacked: true, scaleLabel: { display: true, labelString: 'Overhead, %' } }], xAxes: [{ scaleLabel: { display: true, labelString: 'Bitrate, Mbps' } }] }, animation: { duration: 750, }, } });","title":"SRT Protocol Overhead"},{"location":"protocol/threads/","text":"Threads SRT reference implementation creates the following number of threads: For every UDP socket (UDP multiplexer object): One receiving thread One sending thread One TSBPD thread on every SRT socket with TSBPD mode enabled (enabled by default). One garbage collector thread for the whole SRT intance (application).","title":"Threads"},{"location":"protocol/threads/#threads","text":"SRT reference implementation creates the following number of threads: For every UDP socket (UDP multiplexer object): One receiving thread One sending thread One TSBPD thread on every SRT socket with TSBPD mode enabled (enabled by default). One garbage collector thread for the whole SRT intance (application).","title":"Threads"},{"location":"protocol/congestion-control/","text":"Congestion Control Starting from v1.3.0, SRT provides two types of data transmission: live and file. The mode can be selected via the socket option SRTO_CONGESTION (or more general SRTO_TRANSTYPE option). Live congestion control is used in live transmission mode. In this more the source has a certain rate (either constant or variable). Packets should be transmitted with the same rate as the source. Therefore, the congestion control module does not try to avoid network congestion. It is mainly a reactor on network events. Based on the network conditions (mainly RTT), LiveCC determines when a packet should be considered lost. On the receiving side, liveCC may decide when an ACK is needed prior to ACK timeout. LiveCC also determines the minimum time between consecutive packets are sent. File congestion control is used in file transmission mode. FileCC controls sending pace to avoid network congestion. the only job congestion control module does is to keep sending rate. Useful Links Yunhong Gu. The UDT Congestion Control Algorithm . 2009. Network Congestion Management: Considerations and Techniques","title":"Congestion Control"},{"location":"protocol/congestion-control/#congestion-control","text":"Starting from v1.3.0, SRT provides two types of data transmission: live and file. The mode can be selected via the socket option SRTO_CONGESTION (or more general SRTO_TRANSTYPE option). Live congestion control is used in live transmission mode. In this more the source has a certain rate (either constant or variable). Packets should be transmitted with the same rate as the source. Therefore, the congestion control module does not try to avoid network congestion. It is mainly a reactor on network events. Based on the network conditions (mainly RTT), LiveCC determines when a packet should be considered lost. On the receiving side, liveCC may decide when an ACK is needed prior to ACK timeout. LiveCC also determines the minimum time between consecutive packets are sent. File congestion control is used in file transmission mode. FileCC controls sending pace to avoid network congestion. the only job congestion control module does is to keep sending rate.","title":"Congestion Control"},{"location":"protocol/congestion-control/#useful-links","text":"Yunhong Gu. The UDT Congestion Control Algorithm . 2009. Network Congestion Management: Considerations and Techniques","title":"Useful Links"},{"location":"protocol/congestion-control/file-cc/","text":"File Congestion Control The main goal of File congestion control is to send data at the highest possible rate within the given network conditions. Sending with higher rate than the avalable bandwidth of a link will result in network congestion, forcing huge overhead due to necessity of packet retransmission. Sending with the rate lower, that the available bandwidth, results in underutilization of the network link. FileCC has three operation states: slow start, congestion avoidance and slow down. At the start, there is no information on the network. Congestion control module has to do some probing to determine the available bandwidth and the best sending pace for the normal operation mode - congestion avoidance. In congestion avoidance state, as long as there is no congestion detected (via Loss reports), the sending pace is gradually increased. In case of network congestion, the state is switched to slow down, where the sending pace is reduced to eliminate packet loss in a congested network. Slow Start Slow-start state has an artificial limit on the number of data packets that can be sent before acknowledgment of those segments is received. Slow-start is designed to limit network congestion [1]. File CC starts with 16 DATA packets ( CWND_SIZE=16 ) sent with minimum possible interval. int m_iRCInterval; // SRT Rate control interval Upon ACK Received Only Full ACK triggers Lite ACK do not trigger this case! ACK are processed not more often than every 10 milliseconds ( CUDT::COMM_SYN_INTERVAL_US ). CWND_SIZE is increased to the difference between the acknowledged sequence number since last ACK processing, and the sequence number being acknowledged: CWND_SIZE += LAST_ACK_SEQNO - ACK_SEQNO . If CWND_SIZE exceeds MAX_CWND_SIZE , slow start period ends. MAX_CWND_SIZE=FLOW_WND_SIZE . If delivery rate was reported by the receiver, the inter sending interval is set according to that rate. PKT_SND_PERIOD = 1000000.0 / DELIVERY_RATE where DELIVERY_RATE is filtered with IIR(8) . If delivery rate is not reported, the sending period is set to be PktSndPeriod = CWndSize / (RTT + RCInterval) Upon timers are checked Refer to FileCC::speedupToWindowSize(...) . When CUDT::checkRexmitTimer(...) is called and there is a timeout for the last response from the receiver, then slow start period ends, and the packet send period is set according to the above rules. Congestion Avoidance Upon ACK Upon Loss Report (NACK) References TCP/IP Characteristics. Windows Dev Center. [ WEB ]","title":"File Congestion Control"},{"location":"protocol/congestion-control/file-cc/#file-congestion-control","text":"The main goal of File congestion control is to send data at the highest possible rate within the given network conditions. Sending with higher rate than the avalable bandwidth of a link will result in network congestion, forcing huge overhead due to necessity of packet retransmission. Sending with the rate lower, that the available bandwidth, results in underutilization of the network link. FileCC has three operation states: slow start, congestion avoidance and slow down. At the start, there is no information on the network. Congestion control module has to do some probing to determine the available bandwidth and the best sending pace for the normal operation mode - congestion avoidance. In congestion avoidance state, as long as there is no congestion detected (via Loss reports), the sending pace is gradually increased. In case of network congestion, the state is switched to slow down, where the sending pace is reduced to eliminate packet loss in a congested network.","title":"File Congestion Control"},{"location":"protocol/congestion-control/file-cc/#slow-start","text":"Slow-start state has an artificial limit on the number of data packets that can be sent before acknowledgment of those segments is received. Slow-start is designed to limit network congestion [1]. File CC starts with 16 DATA packets ( CWND_SIZE=16 ) sent with minimum possible interval. int m_iRCInterval; // SRT Rate control interval","title":"Slow Start"},{"location":"protocol/congestion-control/file-cc/#upon-ack-received","text":"Only Full ACK triggers Lite ACK do not trigger this case! ACK are processed not more often than every 10 milliseconds ( CUDT::COMM_SYN_INTERVAL_US ). CWND_SIZE is increased to the difference between the acknowledged sequence number since last ACK processing, and the sequence number being acknowledged: CWND_SIZE += LAST_ACK_SEQNO - ACK_SEQNO . If CWND_SIZE exceeds MAX_CWND_SIZE , slow start period ends. MAX_CWND_SIZE=FLOW_WND_SIZE . If delivery rate was reported by the receiver, the inter sending interval is set according to that rate. PKT_SND_PERIOD = 1000000.0 / DELIVERY_RATE where DELIVERY_RATE is filtered with IIR(8) . If delivery rate is not reported, the sending period is set to be PktSndPeriod = CWndSize / (RTT + RCInterval)","title":"Upon ACK Received"},{"location":"protocol/congestion-control/file-cc/#upon-timers-are-checked","text":"Refer to FileCC::speedupToWindowSize(...) . When CUDT::checkRexmitTimer(...) is called and there is a timeout for the last response from the receiver, then slow start period ends, and the packet send period is set according to the above rules.","title":"Upon timers are checked"},{"location":"protocol/congestion-control/file-cc/#congestion-avoidance","text":"","title":"Congestion Avoidance"},{"location":"protocol/congestion-control/file-cc/#upon-ack","text":"","title":"Upon ACK"},{"location":"protocol/congestion-control/file-cc/#upon-loss-report-nack","text":"","title":"Upon Loss Report (NACK)"},{"location":"protocol/congestion-control/file-cc/#references","text":"TCP/IP Characteristics. Windows Dev Center. [ WEB ]","title":"References"},{"location":"protocol/tsbpd/","text":"TSBPD TSBPD stands for Time-Stamp Based Packet Delivery . The mechanism is described in SRT RFC . An in-depth overview of the latency in SRT is given in the SRT Latency . An overview of SRT latency negotiation and the negotiated latency calculator can be found on the Latency Negotiation page.","title":"TSBPD"},{"location":"protocol/tsbpd/#tsbpd","text":"TSBPD stands for Time-Stamp Based Packet Delivery . The mechanism is described in SRT RFC . An in-depth overview of the latency in SRT is given in the SRT Latency . An overview of SRT latency negotiation and the negotiated latency calculator can be found on the Latency Negotiation page.","title":"TSBPD"},{"location":"protocol/tsbpd/latency-negotiation/","text":"Latency Negotiation SRT connection provides a bidirectional transmission channel. Therefore, there are two buffering latencies (delays): one in each direction. SRT allows to configure both latencies independently using SRTO_RCVLATENCY and SRTO_PEERLATENCY socket options. For simplicity, SRTO_LATENCY can be used to configure both latencies at once. Live Streaming Configuration Only Please note that buffering delay is applied only in Live Streaming configuration whith TSBPD enabled. Let's assume Peer A is the local side on which those socket options are set. Peer B is the remote peer with which Peer A is establising a connection. SRTO_RCVLATENCY is the buffering delay of the Peer A for all the payload it receives. SRTO_PEERLATENCY is the buffering delay of the remote Peer B for all the payload it will receive from Peer A . Peer A uses this delay when sending the payload to decide if it still makes sense to re-transmit a lost packet (see the TL Packet Drop Section of SRT RFC). The same applies relative to Peer B . SRTO_RCVLATENCY is the latency applied on the incoming payload, SRTO_PEERLATENCY is the latency in the direction of sending towards Peer A . Buffering Delay of the Peer SRTO_PEERLATENCY is the receiver buffering latency SRTO_RCVLATENCY of the peer. The negotiated latency is the maximum of SRTO_RCVLATENCY and SRTO_PEERLATENCY pair. Peer A SRTO_RCVLATENCY_NEGOTIATED = max(PEER_A_SRTO_RCVLATENCY; PEER_B_SRTO_PEERLATENCY) . Peer A SRTO_PEERLATENCY_NEGOTIATED = max(PEER_A_SRTO_PEERLATENCY; PEER_B_SRTO_RCVLATENCY) . Peer B SRTO_RCVLATENCY_NEGOTIATED = max(PEER_B_SRTO_RCVLATENCY; PEER_A_SRTO_PEERLATENCY) . Peer B SRTO_PEERLATENCY_NEGOTIATED = max(PEER_B_SRTO_PEERLATENCY; PEER_A_SRTO_RCVLATENCY) . Configured Latency (Before Connection) Set SRT socket options before the connection, and see the negotiated latency after connection is established. Peer A: SRTO_RCVLATENCY SRTO_PEERLATENCY Peer B: SRTO_RCVLATENCY SRTO_PEERLATENCY Reset to Defaults Negotiated Latency (After Connection) Peer A: SRTO_RCVLATENCY SRTO_PEERLATENCY Peer B: var RcvLatencyA = document.getElementById(\"RcvLatencyA\"); var PeerLatencyA = document.getElementById(\"PeerLatencyA\"); var RcvLatencyB = document.getElementById(\"RcvLatencyB\"); var PeerLatencyB = document.getElementById(\"PeerLatencyB\"); var FinalRcvLatencyA = document.getElementById(\"FinalRcvLatencyA\"); var FinalPeerLatencyA = document.getElementById(\"FinalPeerLatencyA\"); var FinalRcvLatencyB = document.getElementById(\"FinalRcvLatencyB\"); var FinalPeerLatencyB = document.getElementById(\"FinalPeerLatencyB\"); var ResetDefaultBtn = document.getElementById(\"ResetDefaultBtn\"); updateRcvAPeerB = function () { let val = Math.max(RcvLatencyA.value, PeerLatencyB.value); FinalRcvLatencyA.value = val; FinalPeerLatencyB.value = val; }; updateRcvBPeerA = function () { let val = Math.max(RcvLatencyB.value, PeerLatencyA.value); FinalRcvLatencyB.value = val; FinalPeerLatencyA.value = val; }; resetDefault = function() { RcvLatencyA.value = 120; RcvLatencyB.value = 120; PeerLatencyA.value = 0; PeerLatencyB.value = 0; updateRcvAPeerB(); updateRcvBPeerA(); } document.addEventListener('DOMContentLoaded', function() { resetDefault(); }, true); ResetDefaultBtn.addEventListener(\"click\", resetDefault); RcvLatencyA.addEventListener(\"input\", updateRcvAPeerB); PeerLatencyB.addEventListener(\"input\", updateRcvAPeerB); RcvLatencyB.addEventListener(\"input\", updateRcvBPeerA); PeerLatencyA.addEventListener(\"input\", updateRcvBPeerA);","title":"Latency Negotiation"},{"location":"protocol/tsbpd/latency-negotiation/#latency-negotiation","text":"SRT connection provides a bidirectional transmission channel. Therefore, there are two buffering latencies (delays): one in each direction. SRT allows to configure both latencies independently using SRTO_RCVLATENCY and SRTO_PEERLATENCY socket options. For simplicity, SRTO_LATENCY can be used to configure both latencies at once. Live Streaming Configuration Only Please note that buffering delay is applied only in Live Streaming configuration whith TSBPD enabled. Let's assume Peer A is the local side on which those socket options are set. Peer B is the remote peer with which Peer A is establising a connection. SRTO_RCVLATENCY is the buffering delay of the Peer A for all the payload it receives. SRTO_PEERLATENCY is the buffering delay of the remote Peer B for all the payload it will receive from Peer A . Peer A uses this delay when sending the payload to decide if it still makes sense to re-transmit a lost packet (see the TL Packet Drop Section of SRT RFC). The same applies relative to Peer B . SRTO_RCVLATENCY is the latency applied on the incoming payload, SRTO_PEERLATENCY is the latency in the direction of sending towards Peer A . Buffering Delay of the Peer SRTO_PEERLATENCY is the receiver buffering latency SRTO_RCVLATENCY of the peer. The negotiated latency is the maximum of SRTO_RCVLATENCY and SRTO_PEERLATENCY pair. Peer A SRTO_RCVLATENCY_NEGOTIATED = max(PEER_A_SRTO_RCVLATENCY; PEER_B_SRTO_PEERLATENCY) . Peer A SRTO_PEERLATENCY_NEGOTIATED = max(PEER_A_SRTO_PEERLATENCY; PEER_B_SRTO_RCVLATENCY) . Peer B SRTO_RCVLATENCY_NEGOTIATED = max(PEER_B_SRTO_RCVLATENCY; PEER_A_SRTO_PEERLATENCY) . Peer B SRTO_PEERLATENCY_NEGOTIATED = max(PEER_B_SRTO_PEERLATENCY; PEER_A_SRTO_RCVLATENCY) .","title":"Latency Negotiation"},{"location":"protocol/tsbpd/latency-negotiation/#configured-latency-before-connection","text":"Set SRT socket options before the connection, and see the negotiated latency after connection is established. Peer A: SRTO_RCVLATENCY SRTO_PEERLATENCY Peer B: SRTO_RCVLATENCY SRTO_PEERLATENCY Reset to Defaults","title":"Configured Latency (Before Connection)"},{"location":"protocol/tsbpd/latency-negotiation/#negotiated-latency-after-connection","text":"Peer A: SRTO_RCVLATENCY SRTO_PEERLATENCY Peer B: var RcvLatencyA = document.getElementById(\"RcvLatencyA\"); var PeerLatencyA = document.getElementById(\"PeerLatencyA\"); var RcvLatencyB = document.getElementById(\"RcvLatencyB\"); var PeerLatencyB = document.getElementById(\"PeerLatencyB\"); var FinalRcvLatencyA = document.getElementById(\"FinalRcvLatencyA\"); var FinalPeerLatencyA = document.getElementById(\"FinalPeerLatencyA\"); var FinalRcvLatencyB = document.getElementById(\"FinalRcvLatencyB\"); var FinalPeerLatencyB = document.getElementById(\"FinalPeerLatencyB\"); var ResetDefaultBtn = document.getElementById(\"ResetDefaultBtn\"); updateRcvAPeerB = function () { let val = Math.max(RcvLatencyA.value, PeerLatencyB.value); FinalRcvLatencyA.value = val; FinalPeerLatencyB.value = val; }; updateRcvBPeerA = function () { let val = Math.max(RcvLatencyB.value, PeerLatencyA.value); FinalRcvLatencyB.value = val; FinalPeerLatencyA.value = val; }; resetDefault = function() { RcvLatencyA.value = 120; RcvLatencyB.value = 120; PeerLatencyA.value = 0; PeerLatencyB.value = 0; updateRcvAPeerB(); updateRcvBPeerA(); } document.addEventListener('DOMContentLoaded', function() { resetDefault(); }, true); ResetDefaultBtn.addEventListener(\"click\", resetDefault); RcvLatencyA.addEventListener(\"input\", updateRcvAPeerB); PeerLatencyB.addEventListener(\"input\", updateRcvAPeerB); RcvLatencyB.addEventListener(\"input\", updateRcvBPeerA); PeerLatencyA.addEventListener(\"input\", updateRcvBPeerA);","title":"Negotiated Latency (After Connection)"},{"location":"protocol/tsbpd/latency/","text":"SRT Latency SRT has an end-to-end latency between the time a packet is given to SRT with srt_sendmsg(...) and the time this very packet is received from SRT via srt_recvmsg(...) . The timing diagram illustrates those key latency points with TSBPD enabled (live mode). End-to-end latency The actual latency on the link will roughly be SRTO_RCVLATENCY + 1/2 \u00d7 RTT 0 , where RTT 0 is the RTT value during the handshake. Packet Delivery Time Packet delivery time is the time point, estimated by the receiver, when a packet should be given (delivered) to the upstream application (via srt_recvmsg(...) ). It consists of the TsbPdTimeBase - the base time difference between sender's and receiver's clock, receiver's buffer delay TsbPdDelay , a timestamp of a data packet PKT_TIMESTAMP , and a time drift Drift . PktTsbPdTime = TsbPdTimeBase + TsbPdDelay + PKT_TIMESTAMP + Drift TSBPD Base Time TsbPdTimeBase is the base time difference between local clock of the receiver, and the clock used by the sender to timestamp packets being sent. A unit of measurement is microseconds. Initial value The value of TsbPdTimeBase is initialized at the time of the conclusion handshake is received as: TsbPdTimeBase = T_NOW - HSREQ_TIMESTAMP . This value roughly corresponds to the one-way network delay ( ~RTT/2 ) between the two SRT peers. TSBPD Wrapping Period The value of TsbPdTimeBase can be updated during the TSBPD wrapping period. The period starts 30 seconds before reaching the maximum timestamp value of a packet ( CPacket::MAX_TIMESTAMP ), and ends whens the timestamp of the received packet is within [30; 60] seconds. CPacket::MAX_TIMESTAMP = 0xFFFFFFFF , or maximum 32-bit unsigned integer value. The value is in microseconds, which corresponds to 1 hour 11 minutes and 35 seconds (01:11:35). In other words, TSBPD time wrapping happens every 01:11:35. During the wrapping period, a packet may have a timestamp either in [ CPacket::MAX_TIMESTAMP - 30s ; CPacket::MAX_TIMESTAMP ] or in [0; 30s]. In the first case, the current value of TsbPdTimeBase is used. In the seconds case, TsbPdTimeBase + CPacket::MAX_TIMESTAMP + 1 is used to calculate TSBPD time for the packet. The wrapping period ends when the timestamp of the received packet is within the interval [30s; 60s]. The updated value will be TsbPdTimeBase += CPacket::MAX_TIMESTAMP + 1 . Time Drift The value of TsbPdTimeBase can be updated by the DriftTracer. Time Drift Sample Upon receipt of an ACKACK packet, the timestamp of this control packet is used as a sample for drift tracing. ACKACK timestamp is expected to be half the round-trip time ago ( RTT/2 ). The drift time DRIFT is calculated from the current time T_NOW ; the TSBPD base time TsbPdTimeBase ; and the timestamp ACKACK_TIMESTAMP of the received ACKACK packet. DRIFT = T_NOW - (TsbPdTimeBase + ACKACK_TIMESTAMP) - \u0394RTT , where \u0394RTT = (RTTSample - RTT0) / 2 or the difference between the current RTT sample calculated from the ACK-ACKACK pair, and the the first RTT sample RTT0 . The motivation for \u0394RTT is to compensate a variation in the network delay from the clock drift estimate. Handshake-based RTT Needed As of SRT v1.4.4 ( PR 1965 ) RTT0 is taken from the very first ACK-ACKACK pair. Assuming it is the best approximation of the actual RTT0 during the handshake. However, the best estimate of the network delay during the handshake would be to estimate RTT based on the exchange of handshakes. The base time should stay in sync with T_NOW - T_SENDER , and should roughly correspond to the network delay ( ~RTT/2 ). The value of ACKACK_TIMESTAMP should represent T_SENDER , and be ~RTT/2 in the past. Therefore, the above equation can be considered as DRIFT = T_NOW - (T_NOW - T_SENDER + T_SENDER) -> 0 if the link latency remains constant. Assuming that the link latency is constant (RTT=const), the only cause of the drift fluctuations should be clock inaccuracy. Drift Tracer should consider RTT Time drift sample in SRT versions before v1.4.4 does not take RTT fluctuations into account. Instead an increase of RTT will be treated as a time drift. See PR 1965 . Drift Tracing and Adjustment Drift tracing is based on accumulating the sum of drift samples. DriftSum - the sum of the time drift samples on a MAX_SPAN number of samples. DriftSpan is the current number of accumulated samples. The default value of MAX_SPAN is 1000 samples. The default value of MAX_DRIFT is 5000 \u03bcs (5 ms). The default value of CLEAR_ON_UPDATE is true . On each DriftSpan sample, the average drift value Drift is updated as Drift = DriftSum / DriftSpan . The values of DriftSpan and DriftSum are reset to 0. If the absolute value of the Drift exceeds MAX_DRIFT ( |Drift| > MAX_DRIFT ), the remainder goes to OverDrift value. The value of OverDrift is used to update the TsbPdTimeBase . In pseudo-code it looks like this: bool update(int64_t driftval) { DriftSum += driftval; ++DriftSpan; if (m_uDriftSpan < MAX_SPAN) return false; if (CLEAR_ON_UPDATE) Overdrift = 0; Drift = DriftSum / DriftSpan; DriftSum = 0; DriftSpan = 0; if (std::abs(Drift) > MAX_DRIFT) { Overdrift = Drift < 0 ? -MAX_DRIFT : MAX_DRIFT; Drift -= Overdrift; } // Drift value was updated return true; } Consider RTTVar before changin the Drift value RTTVar expresses the variation of RTT values over time. Those variations should be considered when Drift is updated. Class DriftTracer The DriftTracer class has the following prototype. template<unsigned MAX_SPAN, int MAX_DRIFT, bool CLEAR_ON_UPDATE = true> class DriftTracer { public: DriftTracer(); public: bool update(int64_t driftval); int64_t drift() const; int64_t overdrift() const; };","title":"SRT Latency"},{"location":"protocol/tsbpd/latency/#srt-latency","text":"SRT has an end-to-end latency between the time a packet is given to SRT with srt_sendmsg(...) and the time this very packet is received from SRT via srt_recvmsg(...) . The timing diagram illustrates those key latency points with TSBPD enabled (live mode). End-to-end latency The actual latency on the link will roughly be SRTO_RCVLATENCY + 1/2 \u00d7 RTT 0 , where RTT 0 is the RTT value during the handshake.","title":"SRT Latency"},{"location":"protocol/tsbpd/latency/#packet-delivery-time","text":"Packet delivery time is the time point, estimated by the receiver, when a packet should be given (delivered) to the upstream application (via srt_recvmsg(...) ). It consists of the TsbPdTimeBase - the base time difference between sender's and receiver's clock, receiver's buffer delay TsbPdDelay , a timestamp of a data packet PKT_TIMESTAMP , and a time drift Drift . PktTsbPdTime = TsbPdTimeBase + TsbPdDelay + PKT_TIMESTAMP + Drift","title":"Packet Delivery Time"},{"location":"protocol/tsbpd/latency/#tsbpd-base-time","text":"TsbPdTimeBase is the base time difference between local clock of the receiver, and the clock used by the sender to timestamp packets being sent. A unit of measurement is microseconds.","title":"TSBPD Base Time"},{"location":"protocol/tsbpd/latency/#initial-value","text":"The value of TsbPdTimeBase is initialized at the time of the conclusion handshake is received as: TsbPdTimeBase = T_NOW - HSREQ_TIMESTAMP . This value roughly corresponds to the one-way network delay ( ~RTT/2 ) between the two SRT peers.","title":"Initial value"},{"location":"protocol/tsbpd/latency/#tsbpd-wrapping-period","text":"The value of TsbPdTimeBase can be updated during the TSBPD wrapping period. The period starts 30 seconds before reaching the maximum timestamp value of a packet ( CPacket::MAX_TIMESTAMP ), and ends whens the timestamp of the received packet is within [30; 60] seconds. CPacket::MAX_TIMESTAMP = 0xFFFFFFFF , or maximum 32-bit unsigned integer value. The value is in microseconds, which corresponds to 1 hour 11 minutes and 35 seconds (01:11:35). In other words, TSBPD time wrapping happens every 01:11:35. During the wrapping period, a packet may have a timestamp either in [ CPacket::MAX_TIMESTAMP - 30s ; CPacket::MAX_TIMESTAMP ] or in [0; 30s]. In the first case, the current value of TsbPdTimeBase is used. In the seconds case, TsbPdTimeBase + CPacket::MAX_TIMESTAMP + 1 is used to calculate TSBPD time for the packet. The wrapping period ends when the timestamp of the received packet is within the interval [30s; 60s]. The updated value will be TsbPdTimeBase += CPacket::MAX_TIMESTAMP + 1 .","title":"TSBPD Wrapping Period"},{"location":"protocol/tsbpd/latency/#time-drift","text":"The value of TsbPdTimeBase can be updated by the DriftTracer.","title":"Time Drift"},{"location":"protocol/tsbpd/latency/#time-drift-sample","text":"Upon receipt of an ACKACK packet, the timestamp of this control packet is used as a sample for drift tracing. ACKACK timestamp is expected to be half the round-trip time ago ( RTT/2 ). The drift time DRIFT is calculated from the current time T_NOW ; the TSBPD base time TsbPdTimeBase ; and the timestamp ACKACK_TIMESTAMP of the received ACKACK packet. DRIFT = T_NOW - (TsbPdTimeBase + ACKACK_TIMESTAMP) - \u0394RTT , where \u0394RTT = (RTTSample - RTT0) / 2 or the difference between the current RTT sample calculated from the ACK-ACKACK pair, and the the first RTT sample RTT0 . The motivation for \u0394RTT is to compensate a variation in the network delay from the clock drift estimate. Handshake-based RTT Needed As of SRT v1.4.4 ( PR 1965 ) RTT0 is taken from the very first ACK-ACKACK pair. Assuming it is the best approximation of the actual RTT0 during the handshake. However, the best estimate of the network delay during the handshake would be to estimate RTT based on the exchange of handshakes. The base time should stay in sync with T_NOW - T_SENDER , and should roughly correspond to the network delay ( ~RTT/2 ). The value of ACKACK_TIMESTAMP should represent T_SENDER , and be ~RTT/2 in the past. Therefore, the above equation can be considered as DRIFT = T_NOW - (T_NOW - T_SENDER + T_SENDER) -> 0 if the link latency remains constant. Assuming that the link latency is constant (RTT=const), the only cause of the drift fluctuations should be clock inaccuracy. Drift Tracer should consider RTT Time drift sample in SRT versions before v1.4.4 does not take RTT fluctuations into account. Instead an increase of RTT will be treated as a time drift. See PR 1965 .","title":"Time Drift Sample"},{"location":"protocol/tsbpd/latency/#drift-tracing-and-adjustment","text":"Drift tracing is based on accumulating the sum of drift samples. DriftSum - the sum of the time drift samples on a MAX_SPAN number of samples. DriftSpan is the current number of accumulated samples. The default value of MAX_SPAN is 1000 samples. The default value of MAX_DRIFT is 5000 \u03bcs (5 ms). The default value of CLEAR_ON_UPDATE is true . On each DriftSpan sample, the average drift value Drift is updated as Drift = DriftSum / DriftSpan . The values of DriftSpan and DriftSum are reset to 0. If the absolute value of the Drift exceeds MAX_DRIFT ( |Drift| > MAX_DRIFT ), the remainder goes to OverDrift value. The value of OverDrift is used to update the TsbPdTimeBase . In pseudo-code it looks like this: bool update(int64_t driftval) { DriftSum += driftval; ++DriftSpan; if (m_uDriftSpan < MAX_SPAN) return false; if (CLEAR_ON_UPDATE) Overdrift = 0; Drift = DriftSum / DriftSpan; DriftSum = 0; DriftSpan = 0; if (std::abs(Drift) > MAX_DRIFT) { Overdrift = Drift < 0 ? -MAX_DRIFT : MAX_DRIFT; Drift -= Overdrift; } // Drift value was updated return true; } Consider RTTVar before changin the Drift value RTTVar expresses the variation of RTT values over time. Those variations should be considered when Drift is updated.","title":"Drift Tracing and Adjustment"},{"location":"protocol/tsbpd/latency/#class-drifttracer","text":"The DriftTracer class has the following prototype. template<unsigned MAX_SPAN, int MAX_DRIFT, bool CLEAR_ON_UPDATE = true> class DriftTracer { public: DriftTracer(); public: bool update(int64_t driftval); int64_t drift() const; int64_t overdrift() const; };","title":"Class DriftTracer"}]}